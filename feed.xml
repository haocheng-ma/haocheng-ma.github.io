<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.4">Jekyll</generator><link href="https://mahaocheng.me/feed.xml" rel="self" type="application/atom+xml"/><link href="https://mahaocheng.me/" rel="alternate" type="text/html" hreflang="en"/><updated>2025-08-15T08:54:25+00:00</updated><id>https://mahaocheng.me/feed.xml</id><title type="html">blank</title><subtitle>Haocheng&apos;s academic webpage. </subtitle><entry><title type="html">The VAST Data Platform</title><link href="https://mahaocheng.me/blog/2025/vast-data-platform/" rel="alternate" type="text/html" title="The VAST Data Platform"/><published>2025-08-14T00:00:00+00:00</published><updated>2025-08-14T00:00:00+00:00</updated><id>https://mahaocheng.me/blog/2025/vast-data-platform</id><content type="html" xml:base="https://mahaocheng.me/blog/2025/vast-data-platform/"><![CDATA[<p>Note: 本文是借助 AI 翻译的 VAST 白皮书，原文请见：<a href="https://www.vastdata.com/whitepaper/#TheVASTDataPlatform">The VAST Data Platform</a>.</p> <h2 id="how-it-works">How It Works</h2> <p>VAST Data Platform 是一个统一的、容器化的软件环境，能够为不同的应用场景和使用者提供多样化的数据处理功能。</p> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-08-14-vast-data-platform/1.png" sizes="95vw"/> <img src="/assets/img/2025-08-14-vast-data-platform/1.png" class="img-fluid rounded z-depth-0 mx-auto d-block" width="100%" height="auto" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <p>这是首个同时原生支持结构化表格数据（包括原生写入或通过 Parquet 等开放格式转换而来）、数据流与事件通知（兼容 Kafka 接口）、以及非结构化数据（通过高性能企业级文件协议如 NFS、SMB、S3 获取）的数据平台。平台还集成了无服务器计算引擎（支持 Python 编写的函数），使数据“活”起来，构建出一个支持递归式 AI 计算的执行环境。数据事件可触发函数运行，例如自动编目、AI 推理、元数据增强，乃至进一步的 AI 模型再训练。通过将数据与代码深度结合，系统可以在新数据和长期数据上持续执行计算任务，实现“实时学习”，通过当前交互与历史经验的联动，让系统愈发智能。</p> <p>不同于传统的批处理架构，VAST 架构利用实时写缓冲区，在数据写入系统的过程中立即捕获并处理数据。无论是小规模、随机的写操作（如事件流、数据库写入），还是大规模并行写操作（如应用生成的检查点文件），都能被即时写入持久性内存中，并能立刻用于检索和与系统中其他数据集的相关性分析。系统的核心数据大多存储在低成本、具备超大规模能力的闪存归档存储中，使得整个平台兼顾实时性与经济性。</p> <p>该平台专注于深度学习任务，致力于从非结构化数据中提取和编排结构信息，构建起基于自然世界感知数据的自动化与发现引擎，从而为 AI 推理与认知提供坚实的数据基础。</p> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-08-14-vast-data-platform/2.png" sizes="95vw"/> <img src="/assets/img/2025-08-14-vast-data-platform/2.png" class="img-fluid rounded z-depth-0 mx-auto d-block" width="100%" height="auto" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <p>系统的各项功能模块被整合进一个统一的平台中，主要由以下几个核心组件构成：</p> <p><strong>VAST DataStore</strong> 是整个平台的存储基础，前身即 VAST 的 Universal Storage（通用存储）产品。它负责将数据持久化，并通过多种协议对外提供读写访问，满足不同应用的接入需求。DataStore 可在单一数据中心扩展至艾字节（Exabyte）级别，打破了长期以来在存储系统中“性能与容量不可兼得”的固有限制，使用户能够在一层成本可控的闪存介质上同时管理文件、对象和表格数据，从而实现任意规模、任意深度的数据计算能力。</p> <p>DataStore 的核心使命是采集并服务于来自自然世界的大量原始、非结构化及流式数据。为了进一步组织这些数据，</p> <p><strong>VAST DataBase</strong> 作为平台的数据库管理服务，负责将结构化表格数据写入系统，并支持对庞大的表格数据和已编目的元数据进行实时、细粒度的查询。不同于传统数据库系统，VAST DataBase 同时具备 OLTP 行式数据库的事务能力、列式数据结构的分析查询性能（如基于闪存的数据仓库），以及数据湖级别的规模与成本优势。</p> <p>DataBase 的最终使命，是组织 DataStore 中的数据知识语料，并对非结构化数据进行语义层面的编目与理解。</p> <p><strong>VAST DataEngine</strong> 是该平台的声明式函数执行环境，支持类似 AWS Lambda 的无服务器函数部署与事件通知功能，运行于标准 Linux 容器中。它内建调度器与成本优化器，可在 CPU、GPU 和 DPU 架构上运行，充分利用可扩展的通用计算资源，使数据具备“计算生命”。与传统计算方法不同，DataEngine 架起了事件驱动架构与数据驱动架构之间的桥梁，能够让系统实时接入、分析、推理并训练来自各类数据的洞察结果。</p> <p>DataEngine 的最终使命，是通过推理与分析，理解数据背后的特征，将原始的非结构化数据转化为有意义的信息。</p> <p><strong>VAST DataSpace</strong> 则进一步将上述能力扩展至多个数据中心之间，构建起统一的计算结构和存储命名空间，旨在打破地理分布式计算中的经典瓶颈。DataSpace 通过元数据同步和远程缓存，实现全球范围的数据访问，并允许各个站点在精细粒度（如文件级、对象级、表格级）上临时接管一致性管理。借助这种去中心化且细粒度的控制方式，VAST Data Platform 成为一个全球性数据平台，在保证严格应用一致性的同时，也为远程函数提供了高性能支持。DataSpace 通过智能预取与数据流水线机制，不仅打通了信息孤岛，还能保持数据管道充盈，让远程 CPU 与 GPU 时刻保持高效运转。</p> <p>DataEngine 也可以灵活叠加在这个统一命名空间之上，在“数据重于计算资源”的场景中将函数调度至数据侧执行；反之，在数据侧计算资源紧张时将数据传送到函数所在位置，从而有效对抗“计算重力”和“数据重力”，助力组织构建全球性的 AI 计算环境。</p> <p>DataSpace 的最终使命，是作为平台连接自然世界的接口，实现全球访问能力，支持跨地域的联邦式 AI 训练与推理任务。</p> <p>现在你已经对 VAST Data Platform 有了基本了解，我们可以回顾大数据与深度学习工作负载的典型需求，看看 VAST 平台在各项关键指标上的契合程度：</p> <table> <thead> <tr> <th>Category</th> <th>Big Data</th> <th>Deep Learning</th> <th>VAST Data Platform</th> </tr> </thead> <tbody> <tr> <td>Data Types</td> <td>Structured &amp; Semi-Structured, Tables, JSON, Parquet</td> <td>Unstructured Text, Video, Instruments, etc.</td> <td>Structured and Unstructured</td> </tr> <tr> <td>Processor Type</td> <td>CPUs</td> <td>GPUs, AI Processors &amp; DPUs</td> <td>Orchestrates across and manages CPU, GPU, DPU, etc.</td> </tr> <tr> <td>Storage Protocols</td> <td>S3</td> <td>S3, RDMA file for GPUs</td> <td>S3, NFSoRDMA, SMB</td> </tr> <tr> <td>Dataset Size</td> <td>TB-scale warehouses</td> <td>TB–EB scale volumes</td> <td>100 TB – EBs</td> </tr> <tr> <td>Namespace</td> <td>Single-Site</td> <td>Globally-Federated</td> <td>Globally-Federated</td> </tr> <tr> <td>Processing Paradigm</td> <td>Data-Driven (Batch)</td> <td>Continuous (Real-Time)</td> <td>Real-time and batch</td> </tr> </tbody> </table> <h2 id="architecting-the-vast-data-platform">Architecting the VAST Data Platform</h2> <p>VAST Data Platform 的架构由一组服务进程组成，这些进程既相互通信，也与外部客户端交互，共同提供丰富的数据服务。为了更清晰地解释这些服务及其协作方式，可以将它们类比为类似 OSI 网络模型七层结构中的“分层服务”。</p> <p>不过，与 OSI 模型那种具有严格分层、各层协议边界清晰的架构不同，VAST 的“分层”更像是一种帮助理解的方式，并不代表系统中真的存在硬性的模块边界。一些服务可能会跨越多个逻辑层级提供功能，同时各层之间的通信也常通过非公开接口完成。换言之，VAST 平台更像是一个灵活协同的服务集合，其架构强调功能融合而非机械分层。</p> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-08-14-vast-data-platform/3.png" sizes="95vw"/> <img src="/assets/img/2025-08-14-vast-data-platform/3.png" class="img-fluid rounded z-depth-0 mx-auto d-block" width="100%" height="auto" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <p>从最底层开始讲起——毕竟每个系统架构都必须建立在坚实的基础之上——VAST 平台的分层结构如下：</p> <p><strong>1. VAST DataStore</strong> 是平台的核心存储层，负责在 VAST 的全球命名空间中存储与保护数据，同时通过传统存储协议（如 NFS、SMB、S3）以及内部协议将数据提供给 VAST DataBase 与 VAST DataEngine 使用。VAST DataStore 本身由三个重要的子层组成：</p> <ul> <li> <p><strong>物理层 / 块管理层（Physical or Chunk Management Layer）</strong> 负责对 VAST Element Store 所使用的小型数据块（chunk）进行基础的数据保护与管理。它涵盖的功能包括：纠删码（Erasure Coding）、数据分布、数据压缩与去重、静态加密（Encryption at Rest）以及设备管理。这一层的作用是保障数据的可靠性、存储效率和底层硬件的运维能力。</p> </li> <li> <p><strong>逻辑层 / VAST Element Store（Logical Layer aka VAST Element Store）</strong> 基于元数据将底层数据块组织成用户可见的高层数据对象（Data Elements），例如文件、对象（object）、表格（table）和卷（volume）等。VAST Element Store 不仅将这些元素统一编入一个全球命名空间（适用于单个 VAST 集群），还可以借助 VAST DataSpace 跨集群构建一个全球一致的分布式命名空间。</p> <p>通俗讲，VAST Element Store 就像是“被伽马射线照射后的文件系统”，它以极强的灵活性将底层数据块整合成跨地域可访问的全局数据元素（如文件、对象、表格、块卷等）。 在这个层面上，系统还提供了路径或元素级的服务功能，如访问控制、数据加密、快照、克隆、数据副本等。</p> </li> <li> <p><strong>协议层（Protocol Layer）</strong> 负责为这些数据元素提供多协议的访问方式。所有协议模块是对等的、独立的，它们可以根据数据类型为外部应用程序提供完整的多协议访问能力。这意味着不论用户使用哪种接口（如 NFS、S3、SMB），都能访问相同的数据元素，并保持数据一致性。</p> </li> </ul> <p><strong>2. 执行层（The Execution Layer）</strong> 负责提供并调度计算逻辑，通过数据驱动的处理方式将数据转化为洞察。该层包含两个核心服务：</p> <ul> <li> <p><strong>VAST DataBase</strong> – 该服务负责管理结构化数据。VAST DataBase 专为满足在线事务处理（OLTP）所需的一致性、数据组织能力以及在线分析处理（OLAP）所需的复杂查询能力而设计，且具备支持当今 AI 应用所需的扩展性。 在逻辑层负责存储表格数据、协议层提供基础 SQL 访问的基础上，VAST DataBase 将这些表格进一步转化为功能完整的数据库管理系统，支持如排序键、外键、连接查询等高级数据库特性。</p> </li> <li> <p><strong>VAST DataEngine</strong> – 该组件赋予系统智能处理能力，使其能对原始数据进行处理、转换，进而推理出有价值的信息。DataEngine 可根据事件触发机制（如满足某一筛选条件的对象到达或某个 Lambda 函数被调用）对数据元素执行任务，如人脸识别、数据泄露防护扫描、视频转码等。<br/> DataEngine 同时作为全球任务调度器，在公有云与私有资源构成的全球网络中，综合计算资源、数据访问性和成本等因素，将计算任务调度至最合适的执行位置。</p> </li> </ul> <p>分层架构本身并不是什么新概念——IT 系统早已习惯于将关系型数据库运行在 SAN 存储之上，再结合如 Kubernetes 这类编排引擎进行调度。但 VAST Data Platform 的革新之处在于： 一是各个服务之间打破了传统层级边界，实现了高度集成； 二是所有这些服务都运行在名为 <strong>DASE（Disaggregated Shared Everything）</strong> 的集群架构上，这种架构解耦了计算与存储资源，又能共享所有数据，从根本上提升了系统的灵活性、可扩展性与性能。</p> <h2 id="the-disaggregated-shared-everything-architecture">The Disaggregated Shared Everything Architecture</h2> <p>VAST Data Platform 是一个软件定义的平台，也就是说，它的所有核心功能都是以软件形式运行在标准的 x86 或 ARM 架构 CPU 上的容器中实现的。但这并不意味着 VAST 是为一堆低配置的 x86 服务器设计的。相反，它结合了最新的存储与网络技术，例如存储级内存（Storage Class Memory）SSD 和基于 NVMe 协议的网络结构（NVMe over Fabrics，简称 NVMe-oF），在一种被称为 <strong>DASE（Disaggregated Shared Everything，解耦共享一切）</strong> 的架构下，使 VAST 集群具备前所未有的可扩展性，彻底打破了过去“共享无物（Shared-Nothing）”和“共享存储介质（Shared-Media）”架构的性能与伸缩性限制。</p> <p>DASE 架构在数据系统集群设计中引入了两个颠覆性的理念：</p> <p><strong>第一，解耦计算资源与持久性数据及系统状态。</strong> 在 DASE 架构中，所有计算任务都由计算节点（称为 VAST Servers，也叫 CNodes）来执行，这些节点运行于无状态的容器中。这包括原本需要由传统存储控制器 CPU 执行的持久存储管理任务。通过这种方式，集群的计算资源可以完全独立于存储容量进行扩展，并可在常规数据中心网络环境中实现弹性部署。</p> <p><strong>第二，共享一切的模型让任意 CNode 都能直接访问所有数据、元数据和系统状态。</strong> 在 DASE 集群中，系统状态被存储在高可用的 NVMe SSD 中，这些 SSD 通过 NVMe JBOF（Just a Bunch of Flash）设备连接，也就是我们通常说的存储机箱。官方称这些设备为 <strong>DBoxes（Data Boxes）</strong>，虽然这个名字现在已经不太常提了。每个 DBox 通过 NVMe 网络结构与计算节点相连，实现所有计算节点对数据的全局直接访问。</p> <p>集群中的每个 CNode 在启动时都会挂载 DASE 集群中的所有 SSD，因此能够直接访问整个系统中共享的状态数据。这些状态数据包括从全局数据压缩信息到数据库事务状态在内的各种“单一真实来源”，并且是统一的、未被分区的。</p> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-08-14-vast-data-platform/4.png" sizes="95vw"/> <img src="/assets/img/2025-08-14-vast-data-platform/4.png" class="img-fluid rounded z-depth-0 mx-auto d-block" width="100%" height="auto" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <p>从上文要点和示意图来看，你可能已经注意到，<strong>DASE 架构主要由两个基本组件组成</strong>：</p> <ul> <li><strong>CNodes（计算节点）</strong>：负责运行平台上的全部软件服务与计算逻辑；</li> <li><strong>DBoxes（数据盒子）</strong>：存放所有的存储介质与系统状态，是平台的持久化存储层。</li> </ul> <h3 id="vast-servers-cnodes">VAST Servers (CNodes)</h3> <p>VAST 服务器，也就是 CNode（计算节点），是 VAST Data Platform 的“智能大脑”，负责整个系统的管理与运作。这些节点的功能包括：保护 VAST Element Store 中的数据、处理数据库查询、判断应将某段体育赛事精彩片段转码到哪个位置以用于下一段回放视频，以及处理整个数据流的计算逻辑。</p> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-08-14-vast-data-platform/5.png" sizes="95vw"/> <img src="/assets/img/2025-08-14-vast-data-platform/5.png" class="img-fluid rounded z-depth-0 mx-auto d-block" width="100%" height="auto" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <p>VAST Data Platform 以一组无状态容器的形式运行在一个或多个 x86 服务器构成的集群上。术语 CNode（即 compute node，计算节点）通常指运行在 VAST 集群中的 VAST Server 容器，但有时也用于指代承载该容器的物理服务器。例如，当你看到类似“每个 CNode 可使用一张 100Gbps 网卡同时处理集群内通信与客户端连接”这样的描述时，这里的 CNode 实际是指运行容器的服务器硬件。</p> <p>在每个 CNode 启动时，都会通过 NVMe-oF 协议挂载整个集群中的所有 SCM（Storage Class Memory）和超大规模闪存 SSD。这意味着，每个 CNode 都可以直接访问整个集群中的所有数据和元数据。在 DASE 架构中，一切资源——每块存储设备、每一个元数据结构、系统内每一个事务状态——都是在所有 CNode 之间共享的。</p> <p>在这种架构中，节点之间没有“所有权”的概念。也就是说，CNode 不拥有任何特定的存储设备或卷的元数据。当某个 CNode 需要读取一个文件时，它会从 SCM SSD 中读取该文件的元数据，以确定数据在超大规模 SSD 上的具体位置，然后直接从这些 SSD 中读取所需数据。整个过程中无需向其他节点请求访问权限。</p> <p>对于常见的简单存储请求（如读取或写入），每个 CNode 都可以自行独立完成，无需与集群中的其他节点协同处理。而对于更复杂的请求，例如数据库查询或 VAST DataEngine 中的函数执行，系统会通过 VAST DataEngine 自动将任务并行分配给多个 CNode 执行。关于这一部分的详细内容，我们将在介绍 VAST DataBase 和 VAST DataEngine 时进一步展开。</p> <h3 id="stateless-containers">Stateless Containers</h3> <p>运行在 DASE 集群中的 CNode 容器是无状态的，这意味着任何会改变系统状态的用户请求或后台任务（例如垃圾回收、设备故障后的重建等）都必须先写入多个 DBox 中的 SSD，在完成写入并确认持久化之前，不会向外发送完成响应。CNode 不会将写入请求或元数据更新缓存在 DRAM 中，甚至也不会使用带电保护的 NVRAM（非易失性内存）作为写缓存。</p> <p>虽然 NVRAM 常被视为“安全的缓存方式”，但它本质上只能防止断电导致的数据丢失，且一旦某两个关键节点同时故障，仍然有可能造成数据丢失，并需要系统执行复杂、容易出错的恢复流程来尝试还原 NVRAM 中的数据。</p> <p>这种设计带来的优势可以通过一个真实案例体现：几年前，美国波士顿地区的一个数据中心（为多所高校提供 HPC 和科研计算服务）发生了一次电力故障。在所有受影响的存储系统中，只有 VAST 集群能在恢复供电后自动恢复运行，而其他系统都需要管理员或厂商介入，手动执行一系列操作才能重新上线。</p> <p>CNode 与 DBox 中 SSD 之间通过 NVMe-oF 建立的超低延迟直连通道，也使得 CNode 无需再在 DRAM 中维护任何读缓存或元数据缓存。当 CNode 需要定位某个数据元素中第 3,451,098 个字节的位置时，它只需以微秒级延迟访问对应的元数据即可。由于不需要缓存机制，CNode 避免了跨节点维护缓存一致性所带来的系统复杂性和大量“东西向”（East-West）网络通信开销。</p> <p>基于容器化的架构，使 VAST Data Platform 能够以软件定义微服务的形式快速部署与弹性扩展，同时也奠定了高可用架构的基础——即使单个容器故障，也不会影响整个系统的运行。相比之下，传统系统为了更新软件版本通常需要重启整台服务器节点，而这过程可能耗费数分钟，尤其在 BIOS 执行内存自检（POST）时更是如此。而在 VAST 系统中，升级 VASTOS 时只需启动一个新的 VASTOS 容器，无需重启主机操作系统，极大地缩短了 VAST 服务器的离线时间，通常只需几秒钟即可完成。</p> <p>这种“无状态容器 + 快速热更新” 的组合，使得 VAST 系统能够在不中断服务的前提下完成几乎所有系统更新操作，包括 BIOS 升级、SSD 固件刷新乃至 SMB 这种有状态协议的更新，真正实现系统级的持续可用性和高可靠性。</p> <h3 id="ha-enclosures-dboxes">HA Enclosures (DBoxes)</h3> <p>所有 VAST 存储机箱（也称为 DBox，Data Box）都是基于 <strong>NVMe-oF（NVMe over Fabrics）</strong> 的高性能存储设备，用于通过超低延迟的 NVMe 网络结构将 SCM（存储级内存）和超大规模闪存 SSD 接入整个系统。这些连接可以基于以太网或 InfiniBand 实现。所有高可用（HA）机箱都采用完全冗余设计，不存在任何单点故障——从 NVMe 路由器（DNode）、SSD、网络接口卡（NIC），到风扇和电源模块，所有关键部件都具备双冗余能力，无论系统规模是 1 台机箱还是 1000 台 HA 机箱，都能确保集群的高可用性。</p> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-08-14-vast-data-platform/6.png" sizes="95vw"/> <img src="/assets/img/2025-08-14-vast-data-platform/6.png" class="img-fluid rounded z-depth-0 mx-auto d-block" width="100%" height="auto" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <p>从上方图示中可以看出，每个 HA Enclosure 内部配备两个 DNode（数据节点），它们负责将来自 NVMe Fabric 网络的请求通过自身的 PCIe 交换芯片路由到本机箱内的 SSD。</p> <p>由于网络端口到 SSD 之间没有任何单点故障，DBox 具备企业级的可靠性和超高吞吐能力。尽管表面上看，DBox 架构类似于传统的双控制器存储阵列，但实际上它在架构设计上存在几个根本性的区别：</p> <ul> <li>DNodes 并不承担任何集群的存储逻辑处理任务，因此即使平台新增功能，DNode 的 CPU 也不会成为系统瓶颈。</li> <li>与传统控制器不同，DNodes 不聚合 SSD，也不提供数据服务，它们仅需执行最基础的逻辑：将每块 SSD 显示到 NVMe Fabric 上，并在微秒级别内完成请求的路由。比如 VAST 的一款 DBox 设备 Ceres，就通过使用基于 ARM 架构的 DPU 作为 DNode，大幅降低了功耗。</li> <li>每个 DBox 内的两个 DNode 以主动-主动（Active-Active）方式运行。在正常情况下，每个 DNode 向 NVMe Fabric 网络呈现一半的 SSD；如果其中一个 DNode 下线，系统会通过 PCIe 交换芯片将原本属于故障节点的 SSD PCIe 通道重映射到剩余的 DNode，整个过程中仍然保持原子写入的一致性，确保数据安全性和连续性。</li> </ul> <h3 id="storage-class-memory">Storage Class Memory</h3> <p>“存储级内存”（Storage Class Memory，简称 SCM）是一类新型存储技术，性能与耐久性远高于传统 NAND 闪存，定位于 <strong>DRAM 与闪存之间的中间层</strong>，具备持久性、低延迟和高写入寿命等特性。</p> <p>在 VAST DataStore 中，SCM SSD 被用作 <strong>高性能写缓冲区</strong> 和 <strong>全局元数据存储层</strong>。选择 SCM 的主要原因是其极低的写入延迟和出色的耐用性，使 DASE 集群能够在无需依赖 DRAM 缓存的前提下，实现亚毫秒级别的写入响应，并显著延长超大规模闪存的寿命。</p> <p>每个 VAST 集群都部署有几十到数百 TB 的 SCM 空间，这为 DASE 架构带来了如下几个关键优势：</p> <ul> <li><strong>优化写入延迟</strong> ：VAST Server 在将数据镜像写入超低延迟的 NVMe SCM 缓冲区后，即可向客户端确认写入成功。这个缓存区将应用层写入请求与底层耗时较高的数据服务操作（如闪存地址转换、数据压缩）隔离开来，同时屏蔽了超大规模闪存较高写延迟对应用的影响。</li> <li><strong>减轻低耐久性闪存的压力</strong> ：数据可长时间停留在 SCM 写缓冲中。由于缓冲区容量远大于传统缓存，它显著降低了超大规模闪存因频繁写入和中间更新所造成的磨损。</li> <li><strong>提升数据保护效率</strong> ：SCM 写缓冲具备足够容量来同时构建多个大规模且分布均衡的数据条带（stripe），并将其以最优的形式写入闪存，从而提升写入效率，使低成本 SSD 的寿命比传统企业级存储系统提高多达 20 倍。</li> <li><strong>规避写放大问题</strong> ：借助 SCM，VAST 集群可以在<strong>数据写入确认之后</strong>、<strong>迁移到超大规模闪存之前</strong>执行压缩、去重等数据优化计算，避免了后处理（post-process）带来的写放大问题，从而提高存储系统的整体寿命与效率。</li> <li><strong>全局数据压缩字典优化</strong> ：SCM 作为全局共享的元数据池，用于存储包括压缩字典在内的各种元数据信息。这使得系统可以应用更高效、更丰富的数据压缩策略，进一步降低基础设施成本，同时避免了传统去重存储设备中“每台服务器都需加载压缩索引至本地内存”的冗余问题。</li> </ul> <h3 id="hyperscale-flash">Hyperscale Flash</h3> <p>超大规模闪存（Hyperscale Flash）指的是像 Facebook、Google 和百度等超大规模互联网公司（Hyperscalers）所采用的一类 SSD，其核心目标是<strong>最大限度降低闪存的成本</strong>。由于这些公司构建存储系统的方式与传统企业级 SAN 阵列完全不同，所使用的闪存也在结构和性能设计上明显区别于企业级 SSD 和消费级 SSD。</p> <p>企业级 SSD 通常用于传统 SAN 系统，这类系统采用双控制器架构，需要 SSD 具备双端口、稳定低延迟的写入性能，因此这些 SSD 配备了昂贵的硬件，如双端口控制器、DRAM 缓存、电源故障保护电路，以及较高比例的预留空间（Overprovisioning）来提升耐用性，适应如 JEDEC 随机 4KB 写入等苛刻的测试标准。</p> <p>相比之下，超大规模公司构建的存储系统使用的是只能连接单端口的服务器，并且大多数数据是以大对象批量写入的形式进行，因此它们所用的 SSD 不需要双端口、DRAM 缓存，也不需要太多预留空间。超大规模闪存主要依赖当前最密集的存储单元——每单元存储 4 位的 QLC（四层单元）NAND，通过直接交付更大容量，实现闪存成本的极限压缩。</p> <p>每个闪存单元多存储一位，就意味着整体容量提升，同时制造成本基本不变，因此可显著降低单位 GB 的成本。然而，存储密度的提升也带来了显著的副作用——闪存的耐用性会随着存储位数的增加而显著下降。例如，第一代 SLC（单层单元）NAND 可承受约 100,000 次擦写，而 QLC 的耐久性则下降了近 100 倍。随着厂商推动下一代 PLC（五层单元）闪存，耐久性预计还会进一步下降。</p> <p>擦除闪存时需要施加高电压，这会在物理层面对闪存单元的绝缘层造成损伤。随着擦写次数的累积，绝缘层损伤越来越严重，最终会导致电子“泄漏”，穿透硅基绝缘体。以 QLC 为例，每个单元需要表示 16 种不同的电压等级（即 4 位数据），通常分布在 0 到 3 伏特之间。随着每个电压等级之间的差距变小，即使少量电子泄漏也可能引起数据错误（比如原本是 1 变成了 0），这就是高密度闪存耐久性变差的根本原因。</p> <p>VAST 的通用存储系统通过两种方式减少闪存磨损：</p> <ol> <li>采用创新的数据结构，能更好地贴合低成本超大规模 SSD 的内部物理结构，这在传统系统中从未尝试过；</li> <li>利用容量巨大的 SCM 写缓冲区来吸收写入压力，从而为写操作留出充足的时间与空间，避免直接磨损闪存。</li> </ol> <p>这两种机制的结合，使得 VAST 能够支持其闪存系统长达 10 年的使用寿命，显著提升了整体系统拥有成本的经济性与可持续性。</p> <h3 id="asymmetric-scaling">Asymmetric Scaling</h3> <p>传统的横向扩展（scale-out）架构通常将计算能力与存储容量绑定在一起，采用以下两种方式之一：要么是“共享无物”架构（shared-nothing），每个节点独立运行一个控制器；要么是“共享介质”架构（shared-media），每组节点共用一对控制器和一组磁盘。无论哪种方式，用户在扩展系统时都被迫同时购买计算资源和存储容量，而且只能在有限的节点配置范围内权衡成本、性能与数据中心资源之间的平衡，例如是选择少量高容量高性能节点，还是选择大量低容量低性能节点。</p> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-08-14-vast-data-platform/7.png" sizes="95vw"/> <img src="/assets/img/2025-08-14-vast-data-platform/7.png" class="img-fluid rounded z-depth-0 mx-auto d-block" width="100%" height="auto" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <p>而 DASE 架构彻底消除了这些限制，其核心设计理念是将计算能力与存储容量完全解耦：计算由 CNode（计算节点） 提供， 存储容量由 DBox（存储机箱） 提供，二者互不依赖。</p> <p>这带来了极大的灵活性：对于训练 AI 模型（这种负载涉及大量小文件随机访问）或运行复杂数据库查询的用户来说，他们可能会为每个 DBox 配置多达 12 个 CNode，以获得足够计算能力；而对于将 VAST 用作冷备份、归档等低活跃数据存储的用户来说，每个 DBox 可能只需不到一个 CNode 就能满足需求。</p> <p>当用户需要扩展容量时，只需新增 DBox，无需同时增加计算资源和功耗——这是传统纵向扩展（scale-up）存储系统中的经典特性，却早已被大多数横向扩展厂商所抛弃。虽然“只扩容”本身已经很经济、很实用，但传统存储厂商在需要提升某一容量下的计算能力时，通常只有两个选择：用“叉车式升级”，替换更强的新节点；增加节点数量，但使用更小容量的硬盘，从而提升每 PB 对应的 CPU 能力。</p> <p>VAST 则提供了更优雅的方式。 当用户发现：AI 引擎能从原本的“冷数据归档”中提取有价值的信息，新版本应用产生了大量的小文件随机访问负载，或者某个应用比预期更受欢迎、使用更广泛时， 他们可以仅通过增加 CNode 数量来扩展计算能力。</p> <p>系统会在这些新加入的 CNode 上自动重新平衡虚拟 IP 地址（VIPs）和计算任务分布，无需手动干预，确保整个集群始终保持最优的性能与资源利用率。</p> <h4 id="asymmetric-and-heterogeneous">Asymmetric and Heterogeneous</h4> <p>对于采用“共享无物”（shared-nothing）架构的用户来说，一旦厂商发布新一代节点产品，他们往往会面临棘手的升级困境。因为在这种架构中，一个存储池内的所有节点必须完全一致，举例来说，如果某客户当前有一个由 16 个已服役 3 年的节点组成的集群，想要扩展 50% 的容量，他面临两种选择：</p> <ul> <li>购买 8 个相同型号的旧节点，并为现有 16 个节点延长技术支持 <ul> <li>问题在于，这类延长支持通常总共最多提供 5~6 年服务周期，这意味着在未来 2~3 年内，客户需要整体更换所有 24 个节点</li> </ul> </li> <li>购买 5 个新型号节点（每个容量是旧型号的两倍）并新建一个存储池 <ul> <li>问题在于系统性能将取决于数据所在的具体存储池</li> <li>多池管理会增加系统复杂性</li> <li>小型新集群在资源利用率和扩展效率上都较差</li> </ul> </li> </ul> <p>情况会更加复杂的是，如果某些新功能（如内联去重、压缩）只能在新型号节点的更强处理器上运行，那旧节点便无法享受这些关键特性，进一步加剧了架构不一致带来的问题。</p> <p>VAST 提出的 DASE 架构是一种“非对称架构”，这并不仅仅是指客户可以通过灵活配置每个存储机箱（DBox）所搭配的 CNode（计算节点）数量，来自由调整每 PB 数据所分配的计算资源。</p> <p>“非对称”还意味着：</p> <ul> <li>在 DASE 系统中，运行 VAST CNode 容器的服务器、DBox 存储机箱以及内部使用的 SSD 都可以异构配置、灵活组合，</li> <li>系统可以在不同代、不同性能、不同规格的组件间协调工作，无需强制“整齐划一”。</li> </ul> <p>VAST 系统能够适配拥有不同核心数量或运行频率的 CNode（计算节点），其方式是将整个集群内的 CNode 视作一个统一的“计算资源池”，类似于操作系统如何在不同 CPU 核心间调度线程一样，VAST 系统会在各个 CNode 之间进行智能任务调度。</p> <p>当系统需要执行后台任务（如 SSD 故障后的数据重建、或将数据从 SCM 写缓冲迁移至超大规模闪存）时，这些任务会被分配给当前利用率最低的服务器。处理能力更强的 CNode 可以完成更多工作，因此系统会自动为其分配更多任务，实现负载均衡与性能最优配比。</p> <p>在存储资源管理上，DASE 系统也采用了类似的思路，将集群中的 SSD（无论是 SCM 还是超大规模闪存）统一管理为一个可用容量池。每个 CNode 都可以直接访问集群内的任意 SSD，同时 DNode 提供了到这些 SSD 的冗余访问路径，因此系统可将 SSD 视作彼此独立的资源和故障域。</p> <p>例如，当一个 CNode 需要申请 SCM 写缓冲区时，它会优先选择两个：空闲写入缓冲空间最多的 SCM SSD，彼此物理距离最远的两块 SSD，并确保这两块 SSD 通过不同的 DNode 连接至 Fabric 网络，若系统中有多个 DBox，则还要分布在不同 DBox 中。</p> <p>同样地，当系统需要在超大规模闪存中分配一个纠删码（erasure-code）条带时，也会优先选择当前可用空间最多、耐用性最好的 SSD，从而实现条带在 SSD 之间的最优分布。</p> <p>由于系统是根据每块 SSD 的剩余容量和剩余寿命来分配任务的，因此在一个集群中，新加入或容量更大的 SSD 会比旧设备承担更多的数据写入和纠删码条带分配任务。直到整个集群中各块 SSD 在磨损程度和空间利用率方面趋于一致，系统才会逐步实现负载均衡。</p> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-08-14-vast-data-platform/8.png" sizes="95vw"/> <img src="/assets/img/2025-08-14-vast-data-platform/8.png" class="img-fluid rounded z-depth-0 mx-auto d-block" width="100%" height="auto" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <p>在 VAST 架构下，当客户的集群需要更多计算能力时，不需要全面升级成新一代、更高性能的节点，而只需按需增加几个新的 CNode（计算节点）即可。这种方式灵活、高效，避免了大规模更换设备带来的成本和复杂性。</p> <h3 id="server-pooling">Server Pooling</h3> <p>在 DASE 架构中，VAST Server（即 CNode）承担着平台计算核心的角色，负责运行 VAST Data Platform 的各种服务，并负责将整个集群与外部网络进行连接。VAST 用户可以将集群中的 VAST Server 划分为多个“资源池”，这种做法有多种应用场景：</p> <p><strong>1. 支持不同类型的网络接入技术</strong><br/> 例如，用户可以将一部分 CNode 配置为带有 Infiniband 网络卡的资源池，用于高性能计算（HPC）集群的数据访问；而另一部分 CNode 配置为配有 100 Gbps 以太网网卡的资源池，用于企业其余基础设施的网络接入。这样就能实现同一个 VAST 存储集群通过不同网络协议支持不同类型的工作负载。</p> <p><strong>2. 实现网络隔离与多租户控制</strong><br/> VAST 管理员可以根据 IP 地址范围限制不同租户或用户对特定视图（View，即多协议共享目录、导出路径或对象桶）的访问权限。通过对不同 CNode 资源池进行划分，可以实现基于位置、用户或业务域的访问隔离，从而提升数据安全性和多租户管理能力。</p> <p><strong>3. 为不同用户、应用或服务提供专属性能</strong><br/> 通过将某些 CNode 专门划分给特定应用、用户组或服务使用，VAST 支持将计算与网络资源“专属化”分配，作为一种积极的服务质量（QoS）保障机制。这种方式可以确保关键业务在高负载环境下也能获得稳定、可预测的性能。</p> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-08-14-vast-data-platform/9.png" sizes="95vw"/> <img src="/assets/img/2025-08-14-vast-data-platform/9.png" class="img-fluid rounded z-depth-0 mx-auto d-block" width="100%" height="auto" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <p>上图所示的 VAST 集群被划分为三个服务器资源池：一个用于运行批处理（更准确地说，是持续型）应用的资源池，一个为交互式用户提供专属性能的资源池，以及一个用于备份应用的资源池。这样的划分确保交互式用户始终拥有足够的性能体验，同时批处理和备份任务彼此之间不会产生干扰。</p> <p>对于更复杂的使用场景，比如动画工作室这样的用户，还可以通过脚本或 VAST Data Engine 的自动化函数，在不同资源池之间动态迁移 CNode。比如在白天将更多计算节点分配给对性能要求较高的美术师使用，等到夜晚美术师下班后，再将这些 CNode 重新分配到渲染资源池，最大化渲染性能利用率。</p> <p>CNode 资源池机制本身就是一种积极型 QoS（服务质量保障）机制，通过控制分配给每个资源池的服务器数量来保证各类任务的性能需求。此外，VAST DataStore 还支持声明式 QoS 策略，可参考本文稍后 “QoS Silences Noisy Neighbors”（QoS 消除“吵闹邻居”效应）一节中对 VAST Element Store 的进一步说明。</p> <p>每个服务器资源池都会分配一组 VIP（虚拟 IP 地址），这些 VIP 会分布在池内的各个 CNode 上。如果某个 CNode 下线，它所负责的 VIP 会自动重新分配给该资源池中其余的节点。VAST 建议每个资源池配置的 VIP 数应为 CNode 数量的 2 到 4 倍，这样一来，即使某个节点出现故障，其负载也可以被多个其他节点共同接管，从而确保服务稳定性。</p> <p>此外，每个 CNode 可以同时隶属于多个资源池，这意味着它可以在处理用户请求的同时，也参与 DASE 集群间的数据复制任务，进一步提升系统的灵活性和资源利用效率。</p> <h3 id="networking-in-dase">Networking in DASE</h3> <p>DASE 集群包含四个主要的逻辑网络，分别承担不同的通信任务：</p> <p><strong>1. NVMe Fabric（后端网络）</strong><br/> 这是连接 CNode（计算节点）与 DNode（存储节点）的内部高速网络。VAST 集群使用基于 RDMA 的 NVMe-oF 协议（NVMe over Fabrics），通常部署在 100 Gbps 的以太网或 InfiniBand 上，其中以太网是默认选项。这个网络是整个系统的数据传输主干，负责在计算与存储之间实现极低延迟的高速通信。</p> <p><strong>2. Host Network（前端网络）</strong><br/> 这是集群对外服务的网络，用于承载来自客户端的文件访问请求、对象存储请求或数据库查询请求。这部分网络负责连接客户端主机与 CNode，是用户与 VAST 集群之间的主要交互通道。</p> <p><strong>3. Management Network（管理网络）</strong><br/> 该网络负责集群的管理通信，包括 DNS 查询、身份验证、管理指令下发等。它通常用于 VAST 管理员对系统的监控、配置和维护操作。</p> <p><strong>4. IPMI Network（硬件管理网络）</strong><br/> 用于对集群中的物理硬件进行底层管理与监控，比如远程控制、硬件健康状态监测、电源管理等，确保系统在底层硬件层面具备可控性和高可用性。</p> <p>根据不同的部署需求，VAST 客户可以选择使用独立物理端口、VLAN 虚拟局域网或两者组合的方式来实现上述逻辑网络，以满足网络设计规范和安全策略的要求。</p> <p>其中最关键的设计决策之一，是<strong>如何将 DASE 集群接入客户的数据中心网络，以提供客户端访问能力</strong>。这不仅影响性能与安全，也关系到整个系统的可扩展性与维护效率。</p> <h4 id="connect-via-switch">Connect via Switch</h4> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-08-14-vast-data-platform/10.png" sizes="95vw"/> <img src="/assets/img/2025-08-14-vast-data-platform/10.png" class="img-fluid rounded z-depth-0 mx-auto d-block" width="100%" height="auto" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <p>“通过交换机连接（Connect via Switch）”模式，是在每个 DASE 集群自带的 NVMe Fabric 交换机上，将<strong>NVMe 后端网络</strong>与<strong>前端主机网络</strong>分别运行在两个不同的 VLAN 上。这两种网络共享同一套交换基础设施。客户的数据中心主机网络通过交换机与 DASE 集群进行连接，方式是将 Fabric 交换机通过 MLAG（多链路聚合）连接至客户核心交换机，如上图中绿色线路所示。</p> <p>在此模式下，每个 CNode 配备一张 100 Gbps 的网络接口卡（NIC）。通过一根分线电缆将这张卡拆分为两个 50 Gbps 的连接口，分别连接到两个 Fabric 交换机中。每条 50 Gbps 连接同时承载两个 VLAN：一个用于 NVMe 后端网络，另一个用于主机数据流量。</p> <p>这种连接方式具有以下优点：</p> <ul> <li>每个 CNode 只需配置一张 RDMA 网络接口卡（RNIC），降低硬件复杂度和成本</li> <li>所有网络流量通过少量 100 Gbps 链路进行汇聚，并通过 MLAG 实现高可用，这样可显著减少对客户主机交换机端口数量的需求</li> </ul> <p>但如果这种方式是“完美方案”，就不会存在其他替代选项。它也有一些限制和不足：</p> <ul> <li>主机网络必须使用与 Fabric 网络相同的网络类型与协议</li> <li>如果集群使用 Infiniband 构建 NVMe Fabric，则只能支持 Infiniband 主机接入，限制较大</li> <li>在 100 Gbps Fabric 中使用 40、25、10 Gbps 的以太网接入时，连接成本较高且不灵活</li> <li>整个集群只能配置一个物理主机网络，不适合有多个前端网络需求的复杂部署环境</li> </ul> <h4 id="connect-via-cnode">Connect via CNode</h4> <p>通过 NVMe Fabric 交换机将 DASE 集群接入客户网络是一种简单、端口使用最少的方式。但正如我们在前文关于“服务器资源池”的部分中所讨论的，有些客户需要在<strong>客户端接入方式或多租户隔离上拥有更高的灵活性与控制权</strong>，这时单一的交换机连接方案就可能显得不够用了。</p> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-08-14-vast-data-platform/11.png" sizes="95vw"/> <img src="/assets/img/2025-08-14-vast-data-platform/11.png" class="img-fluid rounded z-depth-0 mx-auto d-block" width="100%" height="auto" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <p>当 VAST 客户需要将来自多个不同网络、采用不同技术或有不同安全需求的客户端接入同一个 DASE 集群时，可以为 CNode 安装第二张网络接口卡（NIC），这张卡直接连接到该 CNode 所服务的特定网络，从而实现与多个网络的并行连接。</p> <p>“通过 CNode 连接（Connect via CNode）”的优点：</p> <ul> <li>支持通过不同技术协议接入 DASE 集群： <ul> <li>配有 Infiniband 网卡的 CNode 可以服务于 Infiniband 客户端</li> <li>配有 Ethernet 网卡的 CNode 可以服务于以太网客户端</li> <li>或通过 Fabric 交换机为 Ethernet 客户端提供接入</li> </ul> </li> <li>支持接入更高速的前沿网络技术，如 200 Gbps 以太网</li> <li>能够连接多个安全隔离区域（Security Zones），无需配置跨网络路由，简化安全策略管理</li> </ul> <p>但也存在一些缺点：</p> <ul> <li>需要额外的网络接口卡、交换机端口、IP 地址等资源，增加一定的部署与运维成本</li> </ul> <p>正如上文所述，VAST 的架构允许客户灵活混用“通过交换机连接（Connect via Switch）”和“通过 CNode 连接（Connect via CNode）”两种模式。例如，某客户拥有少量 Infiniband 主机，可以仅为部分 CNode 安装 IB 网卡以接入这些主机；而其他以太网客户端则仍通过共享的 Ethernet Fabric 交换机接入集群，从而在满足连接需求的同时，最大限度地减少交换机端口资源的使用。</p> <h4 id="leaf-spine-for-large-clusters">Leaf-Spine for Large Clusters</h4> <p>当 DASE 集群的规模扩大到需要的 NVMe fabric 连接数量超过一对 64 端口交换机所能提供的上限时，原本作为集群核心的一对 Fabric 交换机将演变为一个更大规模的 <strong>Leaf-Spine 网络架构</strong>。</p> <p>在这种扩展架构中，CBox（一个多服务器设备，在单一机箱中运行多个 CNode）和 DBox 仍然连接到一对交换机，但这些交换机不再是集群的“核心”，而是作为 <strong>“叶子（Leaf）”交换机</strong>，并通过冗余连接对接到两台 <strong>Spine（主干）交换机</strong>上。而集群中其他机架顶部的 Leaf 交换机也以同样方式接入 Spine 层，形成完整的 Leaf-Spine 拓扑。</p> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-08-14-vast-data-platform/12.png" sizes="95vw"/> <img src="/assets/img/2025-08-14-vast-data-platform/12.png" class="img-fluid rounded z-depth-0 mx-auto d-block" width="100%" height="auto" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <p>这种 Leaf-Spine 网络结构的优势在于：</p> <ul> <li>支持 DASE 集群 横向扩展至超过 100 台设备（appliances）</li> <li>如果使用高端口数的 director 级 Spine 交换机，可进一步提升扩展上限</li> <li>具备更高的带宽聚合能力和更低的网络延迟，适配 NVMe-oF 对网络性能的极高要求</li> <li>有助于保持 每个 CNode 到任意 DBox 之间都能实现一致的网络性能，即所谓“扁平化网络”</li> </ul> <h2 id="scale-out-beyond-shared-nothing">Scale-Out Beyond Shared-Nothing</h2> <p>在过去十多年里，存储行业一直深信“无共享（shared-nothing）”存储架构是实现存储规模扩展与成本节省的最佳方式。自从 Google 于 2003 年发布其文件系统架构白皮书之后，几乎所有类型的存储系统架构都将“无共享”模式作为标配，包括超融合存储、可扩展文件存储、对象存储、数据仓库系统等。</p> <p>然而，十多年过去了，“无共享”架构所依赖的一些基本前提，如今已不再成立，主要原因如下：</p> <ul> <li>无共享系统最初设计的前提，是将磁盘与处理器（CPU）物理共置，因为当时网络速度远慢于本地存储。然而随着 NVMe over Fabrics（NVMe-oF）的出现，现在即便在远程访问 SSD 和 SCM（存储级内存）时，也能实现高性能，不再需要将 CPU 与存储设备强绑定。</li> <li>无共享架构迫使用户在扩展计算能力和存储容量时必须“打包”进行，导致基础设施扩展缺乏灵活性。相比之下，如果能够根据数据集对访问速度的需求单独扩展 CPU，将更为高效灵活。</li> <li>无共享系统限制了存储效率。因为每个节点都“拥有”一部分存储介质，为了容错，就必须在节点之间进行纠删码（erasure coding），这限制了条带（stripe）的宽度与切片（shard）效率；同时还需在多个节点复制数据缩减的元数据，影响了数据压缩与去重的效率。而在“全共享（shared-everything）”架构中，没有任何一台机器专属某些 SSD，因此可以构建更宽、更高效的 RAID 条带结构，并集中管理全局数据缩减元数据，提升整体存储效率。</li> <li>随着容器成为部署应用程序的主流方式，这种基于微服务的架构模式也受益于容器本身的“无状态”特性。在数据本地性不再构成瓶颈的前提下，存储服务可以轻松在可组合基础设施中快速部署与弹性扩展。</li> </ul> <h3 id="the-advantages-of-a-stateless-design">The Advantages of a Stateless Design</h3> <p>当一台 VAST 服务器（称为 CNode）接收到读取请求时，该 CNode 会从共享的存储级内存（SCM）中读取 VAST DataStore 的持久化元数据，以定位被请求的数据具体存储在哪些位置。接着，它会直接从超大规模闪存（hyperscale flash）中读取该数据（如果数据尚未从写入缓冲区迁移，则直接从 SCM 读取），并将数据返回给发起请求的客户端。对于写入请求，VAST 服务器会将数据和元数据直接写入多块 SSD 中，然后再向客户端返回写入成功的响应。</p> <p>通过在超低延迟的网络结构中直接访问共享设备，VAST 服务器无需彼此通信即可完成 I/O 请求的处理——在读写路径中，任何机器都不需要与其他机器进行同步通信。“全共享”（Shared-Everything）架构让性能扩展变得非常简单，只需添加更多的 CPU 即可线性提升性能，从而突破传统“无共享”架构在扩展过程中常见的收益递减问题。用户可以构建由数千台 VAST 服务器组成的大型集群，实现极致的整体性能。VAST 集群规模的主要限制因素是客户部署的网络结构的容量。</p> <p>将系统所有元数据存储在通过超低延迟网络连接的共享 SSD 上，意味着 CNode 无需缓存元数据，因此也不需要在服务器之间维持元数据缓存一致性。而且，因为所有数据在写入时都已同步写入持久性的 SCM SSD 中（而不是先缓存在易失性 DRAM 中），就不再需要传统写缓存常用的断电保护硬件。这种做法将完全非易失性存储介质与事务性存储语义相结合，从而确保 VAST Element Store 的更新始终具备一致性和持久性。</p> <p>DASE 架构也彻底消除了传统存储架构中“存储设备必须归某台控制器节点或其冗余对控制”的需求。由于集群中所有 SCM 和超大规模闪存 SSD 都对所有 CNode 共享，任意一台 CNode 都可以从头到尾独立完成请求的处理。这意味着哪怕一整个 VAST 集群中只剩下一台服务器可用，集群依然可以保持完整运行、继续提供所有的数据服务。例如，如果一个集群由 100 台服务器组成，即使其中 99 台失效，剩下的那一台仍可支撑整个系统 100% 正常在线运行。</p>]]></content><author><name></name></author><category term="Storage"/><category term="VAST"/><category term="SSD"/><category term="Cluster"/><summary type="html"><![CDATA[The translated version of white paper — the VAST data platform.]]></summary></entry><entry><title type="html">Key management in TPM based security</title><link href="https://mahaocheng.me/blog/2025/tpm-based-security/" rel="alternate" type="text/html" title="Key management in TPM based security"/><published>2025-07-24T00:00:00+00:00</published><updated>2025-07-24T00:00:00+00:00</updated><id>https://mahaocheng.me/blog/2025/tpm-based-security</id><content type="html" xml:base="https://mahaocheng.me/blog/2025/tpm-based-security/"><![CDATA[<p>TPM（可信平台模块）本质上并不会直接存储完整的密钥，而是持久化存储称为 Seed（种子）的秘密值，并通过这些 Seed 确定性地派生出各种密钥。两类常见的 Seed 和对应的密钥体系是 Endorsement 和 Stroage，如下所示：</p> <table> <thead> <tr> <th>Seed 类型</th> <th>密钥体系</th> <th>用途简述</th> </tr> </thead> <tbody> <tr> <td>Endorsement Seed</td> <td>Endorsement Key（EK）</td> <td>识别 TPM 的密钥</td> </tr> <tr> <td>Storage Seed</td> <td>Storage Root Key（SRK）</td> <td>本地应用使用的密钥</td> </tr> </tbody> </table> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-07-24-tpm-based-security/key_management.png" sizes="95vw"/> <img src="/assets/img/2025-07-24-tpm-based-security/key_management.png" class="img-fluid rounded z-depth-0 mx-auto d-block" width="100%" height="auto" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <div class="caption">     Figure 1. Endorcement and Storage types in TPM Key Management </div> <p>上述密钥按照用途分为两类：Restricted 和 Non-Restricted。</p> <ul> <li>Restricted：用于签名或者解密 TPM 的状态和数据，例如，签名启动度量值、证明某个密钥位于同一个 TPM，EK、SRK、AIK 都在此类；</li> <li>Non-Restricted：用于一般用途，例如，TLS 客户端的密钥、签名普通文档的密钥，应用密钥（Application Key）属于此类。</li> </ul> <h2 id="endorsement-key">Endorsement Key</h2> <p>Endorsement Key（EK）是 TPM 的身份标识，由 TPM 制造商配置。</p> <ul> <li>EK 公私钥对由已知模板（EK Template）、Endorsement Primary Seed（EPS）和选定的密钥派生函数（KDF）、通过 <code class="language-plaintext highlighter-rouge">TPM2_CreatePrimary()</code> 确定性生成；</li> <li>EK 证书由TPM制造商的证书颁发机构（CA）签发并将其存储到 TPM NVRAM；</li> <li>EK 证书包含EK公钥以及其他字段，例如，TPM 制造商名称、组件型号、组件版本、密钥 ID 等。</li> </ul> <p>EK Template 的具体格式可查阅：<a href="https://trustedcomputinggroup.org/wp-content/uploads/TCG_IWG_EKCredentialProfile_v2p3_r2_pub.pdf#page=37">Default EK Template (TPMT_PUBLIC): RSA 2048 (Storage)</a></p> <p>EK 被存储在 TPM Shielded Location，私钥永远不能暴露，公钥可从 TPM 内读取。</p> <p>关于 TPM 的安全存储有两个概念：</p> <ul> <li>Isolated Locations：安全系统的非易失性存储，具有访问控制能力，不允许来自系统边界外的访问；</li> <li>Shielded Locations：具有防篡改能力的 Shielded Location，通常用于存储秘密值；</li> </ul> <h2 id="storage-root-key">Storage Root Key</h2> <p>在 TPM 的 Storage 体系结构中，密钥的创建遵循树状层级结构：</p> <ul> <li>比如 Attestation Key（AK）或应用密钥，都是在 TPM 的存储体系下生成的；</li> <li>这些密钥的父密钥是 SRK（Storage Root Key），SRK 是 TPM 中的一个根密钥，用于保护和派生其他密钥；</li> <li>而这些密钥的 key attestation（密钥认证） 则由 EK（Endorsement Key） 来实现。</li> </ul> <p>换句话说，Key attestation 是一种通过签名链建立信任的过程，核心目的是构建一条从 EK 一直到某个具体密钥（如 AK）的信任链。</p> <h2 id="attestation-key">Attestation Key</h2> <p>Attestation Key（AK）是一种用于对 TPM 内部数据进行签名的密钥，具有以下关键特性：</p> <ul> <li>non-duplicable（不可复制）：AK 是由 TPM 内部直接生成的，并且密钥材料不会暴露给 TPM 外部，这确保了其私钥无法被导出或复制，增强了安全性。</li> <li>Restricted（受限用途）：AK 只能用于对 TPM 生成的数据进行签名或解密，例如 PCR（平台配置寄存器）值。它不能用于任意数据的签名或加密，以防止其被滥用为通用密钥。</li> <li>签名密钥，用于设备身份（DevID）：AK 的公钥证书可以作为设备的身份凭据，由制造商或受信任方签发。</li> </ul> <p><em>“The 802.1AR standard defines a secure device identifier (DevID) as “an identifier that is cryptographically bound to a device”.”</em></p> <p>设备制造商在制造阶段创建的设备身份称为 IDevID/IAK，IDevID “Credential” 在设备整个生命周期内使用。用户在部署/应用阶段创建的设备身份称为 LDevID/LAK，LDevID “Credential” 会在设备复位或寿命结束时被移除。</p> <p><em>“Credential is a combination of a private key and a certificate.”</em></p> <p>Attestation Identity Key（AIK）是 TPM 1.2 中的一种密钥类型，AIK 仅被允许执行两种基于签名的操作：</p> <ul> <li>TPM_Quote：使用 AIK 对 PCR 寄存器值进行签名，生成代表设备身份和当前状态的硬件报告，常用于远程证明场景，也就是向远端证明设备当前的可信状态。</li> <li>TPM_CertifyKey：生成一个签名声明，用以证明另一个密钥（不是 AIK 本身）位于 TPM 的密钥存储体系中，且不可迁移（non-migratable）。显然，所认证的那个密钥必须实际具备这些属性。</li> </ul> <h2 id="credential-activation">Credential Activation</h2> <p>Credential activation 能够远程地建立对新密钥（例如，IAK）的信任，该密钥随后可以代表设备进行加密或证明，需要证明如下两点：</p> <ul> <li> <p>IAK（Identity Attestation Key）具备预期的密钥属性，例如：</p> <div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code> <span class="n">FlagFixedTPM</span>             <span class="c1">// 密钥不能被导出，必须留在 TPM 中；</span>
 <span class="n">FlagSensitiveDataOrigin</span>  <span class="c1">// 密钥必须由 TPM 内部生成，而不是导入；</span>
</code></pre></div> </div> </li> <li> <p>IAK 确实与 EK 存在于相同的 TPM 中。</p> </li> </ul> <p><em>Credential activation allows a remote party to verify one key is on the same TPM as another key, and that the key has a specific set of properties.</em></p> <p>大概的流程如下：Activation key 代指 IAK，Anchor key 代指 EK。</p> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-07-24-tpm-based-security/credential_activation.png" sizes="95vw"/> <img src="/assets/img/2025-07-24-tpm-based-security/credential_activation.png" class="img-fluid rounded z-depth-0 mx-auto d-block" width="100%" height="auto" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <div class="caption">     Figure 2. The Flow of Credential Activation </div> <ul> <li>Client 将 IAK 的公钥、EK 的公钥和 IAK 的密钥属性发送给 Server；</li> <li> <p>Server 验证 IAK 的属性是否满足安全策略、生成秘密值并构造 Challenge，形式如下，然后返回给 Client：</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>   Challenge = ENC{secret} | aes_key1
               ENC{key1}  | aes_key2
               ENC{seed}  | EK_pub
</code></pre></div> </div> <p>其中，<code class="language-plaintext highlighter-rouge">aes_key1</code> 是随机生成的对称密钥；<code class="language-plaintext highlighter-rouge">aes_key2 = KDF(seed, IAK name)</code>：KDF 是密钥派生函数，IAK name 是 IAK 公钥 Blob（包含属性）的哈希；所有敏感数据都用 EK 公钥加密，确保只能由目标 TPM 解密。</p> </li> <li>Client 将 Challenge 发送给 TPM，调用 <code class="language-plaintext highlighter-rouge">ActivateCredential</code> 命令；</li> <li>TPM 内部只有在拥有与 Challenge 匹配的 EK 和 IAK 的前提下，才能正确解密并返回秘密值。成功解密即意味着：IAK 存在于该 TPM 中；IAK 拥有正确的密钥属性。</li> </ul> <h2 id="reference">Reference</h2> <ol> <li><a href="">https://ericchiang.github.io/post/tpm-keys/</a></li> <li><a href="">https://tpm2-software.github.io/tpm2-tss/getting-started/2019/12/18/Remote-Attestation.html</a></li> <li><a href="">https://github.com/google/go-attestation/blob/master/docs/credential-activation.md</a></li> <li><a href="">https://github.com/tpm2dev/tpm.dev.tutorials</a></li> </ol>]]></content><author><name></name></author><category term="cc"/><category term="tpm"/><category term="measurement"/><category term="attestation"/><summary type="html"><![CDATA[TPMs are ridiculously complex.]]></summary></entry><entry><title type="html">Remote attestation for confidential VMs using grub boot</title><link href="https://mahaocheng.me/blog/2025/attest-grub-boot/" rel="alternate" type="text/html" title="Remote attestation for confidential VMs using grub boot"/><published>2025-03-08T00:00:00+00:00</published><updated>2025-03-08T00:00:00+00:00</updated><id>https://mahaocheng.me/blog/2025/attest-grub-boot</id><content type="html" xml:base="https://mahaocheng.me/blog/2025/attest-grub-boot/"><![CDATA[<p>Based on the analysis of measurement and attestation techniques, we propose a solution to establish trust for confidential VMs (CVMs) booting via firmware (aka grub boot). The measured boot follows the <a href="https://uefi.org/specs/UEFI/2.10/38_Confidential_Computing.html#">UEFI specification for confidential computing</a>, details please refer to my previous article. Next, We developed a software development kit (SDK) and open-sourced it in the <a href="https://gitee.com/openeuler/virtCCA_sdk">openEuler/virtCCA_sdk</a>. It provides a suite of tools and libraries to enable remote attestation for grub boot. Today, we’ll take a deep dive into this SDK.</p> <h2 id="overview-of-attestation-case">Overview of attestation case</h2> <p>We provices a simple demo <a href="https://gitee.com/openeuler/virtCCA_sdk/tree/master/attestation/samples">attestation/samples</a> to showcase virtCCA attestation, consisting of a client and a server. The server runs inside the CVM, while the client runs locally (e.g., on a user machine). The client simulates a user with a local verifier and key management. The server uses the <a href="https://gitee.com/openeuler/virtCCA_sdk/tree/master/attestation/sdk">attestation/sdk</a> to get the device certificate and attestation report (aka attestation token), while the client parses and verifies them. If a CVM boots via grub boot, the server also collects event logs to support attestation. The server and client communicate over TCP. Another demo featuring TLS transmission is available in <a href="https://gitee.com/openeuler/virtCCA_sdk/tree/master/attestation/rats-tls">attestation/rats-tls</a>. <em>Please note that these demos are for reference only.</em></p> <p>Below outlines the interaction between the client and the server:</p> <pre><code class="language-mermaid">sequenceDiagram
  participant Client as Client
  participant Server as Server
  Client -&gt;&gt; Client: Export Reference Values of Measurements
  Client -&gt;&gt; Server: Send DEVICE_CERT_MSG_ID request
  Server -&gt;&gt; Client: Return Device Certificate
  Client -&gt;&gt; Server: Send ATTEST_MSG_ID with random Challenge
  Server -&gt;&gt; Client: Return Attestation Token
  alt Grub Boot (Firmware-Only Boot)
    Client -&gt;&gt; Server: Send CCEL_ACPI_TABLE_ID request
    Server -&gt;&gt; Client: Return CCEL ACPI Table Data
    Client -&gt;&gt; Server: Send CCEL_EVENT_LOG_ID request
    Server -&gt;&gt; Client: Return CC Event Log Data
  end
  Client -&gt;&gt; Client: Verify Device Certificate and Attestation Token
  Client -&gt;&gt; Server: Send Verification Result (VERIFY_SUCCESS_MSG_ID / VERIFY_FAILED_MSG_ID)
  alt Full Disk Encryption Enabled
    Client -&gt;&gt; Server: Send Rootfs Key File Data
  end
</code></pre> <p>From the client’s perspective, the above process can be broken down into:</p> <ul> <li> <p>At first of all, you need to set reference values of measurements.</p> </li> <li> <p>Obtain the device certificate to represent the identity of a CVM.</p> </li> <li> <p>Obtain the attestation token signed by attestation key, it will include a challeng sent by you.</p> </li> <li> <p>If grub boot is enabled, the confidential computing event log (CCEL) ACPI table and CCEL data is also required.</p> </li> <li> <p>Verify the device certificate and attestation token with the support of endorsements and reference values.</p> </li> <li> <p>If full disk encryption (FDE) is enabled, the key file of root file system (rootfs) is delivered upon successful verification.</p> </li> </ul> <p><strong>Example Commands</strong></p> <ul> <li>Run attestation samples for grub boot:</li> </ul> <div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Run server inside the CVM</span>
./server <span class="nt">-i</span> 127.0.0.1 <span class="nt">-p</span> 12345

<span class="c"># Run client locally like user machine</span>
./client <span class="nt">-i</span> 127.0.0.1 <span class="nt">-p</span> 12345 <span class="se">\</span>
         <span class="nt">-m</span> 38d644db0aeddedbf9e11a50dd56fb2d0c663f664d63ad62762490da41562108 <span class="se">\</span>
         <span class="nt">-f</span> image_reference_measurement.json
</code></pre></div></div> <h2 id="how-to-generate-reference-measurements">How to generate reference measurements?</h2> <p>we provide two tools to calculate reference valued of measurements, corresponding to the parameters specified with <code class="language-plaintext highlighter-rouge">-m</code> and <code class="language-plaintext highlighter-rouge">-f</code> in the example command. The parameter following <code class="language-plaintext highlighter-rouge">-m</code> represents the reference value for the CVM’s initial measurement, calculated using the <a href="https://gitee.com/openeuler/virtCCA_sdk/tree/master/attestation/rim_ref">gen_rim_ref</a> tool. The JSON file specified with <code class="language-plaintext highlighter-rouge">-f</code> contains reference measurements of the CVM image, including the grub binary, grub configuration, kernels, and corresponding initramfs images. This file is generated by the <a href="https://gitee.com/openeuler/virtCCA_sdk/tree/master/cvm-image-rewriter">cvm-image-rewriter</a> tool.</p> <h3 id="reference-value-of-cvm-initial-measurement">Reference value of CVM initial measurement</h3> <p>The tool <code class="language-plaintext highlighter-rouge">gen_rim_ref</code> is similar to <a href="https://github.com/veraison/cca-realm-measurements">cca-realm-measurements</a>. Given a VM configuration (e.g., number of vcpu) and the payload (e.g., firmware binary) to run in the CVM, this tool calculates the CVM Initial Measurements needed for attestation.</p> <h3 id="reference-values-of-cvm-image">Reference values of CVM image</h3> <p>The <code class="language-plaintext highlighter-rouge">cvm-image-rewriter</code> tool is used to create, customize and/or measure theCVM image (.qcow2) to support grub boot and attestation. it computes the SHA-256 hashes of components in CVM image, such as grub binary (BOOTAA64.EFI), grub configuration (grub.cfg), kernels and corresponding initramfs images. These hashes are saved in a JSON file (image_reference_measurement.json), and will be used as reference measurements in attestation.</p> <p>Tp be more specific, this tool mounts the CVM image using <code class="language-plaintext highlighter-rouge">guestmount</code>, then measures its boot components.</p> <ul> <li>Grub image and Configuration Measurements:</li> </ul> <p>It compiles a C program (measure_pe.c) to create the MeasurePe binary used to calculate the SHA-256 hash of the GRUB EFI binary (BOOTAA64.EFI). It also computes the SHA-256 hash for the GRUB configuration file.</p> <ul> <li>Kernel and Initramfs image Measurements:</li> </ul> <p>This function scans the <code class="language-plaintext highlighter-rouge">/boot</code> directory within the mounted image for kernel images (excluding rescue kernels).</p> <p>For each found kernel (named vmlinuz-*), it attempts to uncompress the image, calculates its SHA-256 hash, and then measures the corresponding initramfs image.</p> <p>These measurements are aggregated into a JSON file named image_reference_measurement.json with the following structure:</p> <div class="language-json highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">{</span><span class="w">
    </span><span class="nl">"grub"</span><span class="p">:</span><span class="w"> </span><span class="s2">"&lt;GRUB EFI hash&gt;"</span><span class="p">,</span><span class="w">
    </span><span class="nl">"grub.cfg"</span><span class="p">:</span><span class="w"> </span><span class="s2">"&lt;GRUB config hash&gt;"</span><span class="p">,</span><span class="w">
    </span><span class="nl">"kernels"</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="w">
        </span><span class="p">{</span><span class="w">
            </span><span class="nl">"version"</span><span class="p">:</span><span class="w"> </span><span class="s2">"&lt;kernel version&gt;"</span><span class="p">,</span><span class="w">
            </span><span class="nl">"kernel"</span><span class="p">:</span><span class="w"> </span><span class="s2">"&lt;kernel hash&gt;"</span><span class="p">,</span><span class="w">
            </span><span class="nl">"initramfs"</span><span class="p">:</span><span class="w"> </span><span class="s2">"&lt;initramfs hash&gt;"</span><span class="w">
        </span><span class="p">},</span><span class="w">
        </span><span class="err">...</span><span class="w">
    </span><span class="p">],</span><span class="w">
    </span><span class="nl">"hash_alg"</span><span class="p">:</span><span class="w"> </span><span class="s2">"sha-256"</span><span class="w">
</span><span class="p">}</span><span class="w">
</span></code></pre></div></div> <p>This JSON file will be used in attestation, serving as reference measurements of the CVM image.</p> <h2 id="how-to-verify-attestation-token">How to verify attestation token?</h2> <p>The detailed process for “Verify Device Certificate and Attestation Token” is shown as follows.</p> <pre><code class="language-mermaid">flowchart TD
    A["Verify Certificate Chain"] --&gt; B["Verify Token Signature"]
    B --&gt; C["Check Challenge and RIM"]
    C -- Direct Kernel Boot --&gt; D["Pass Verification"]
    C -- Grub Boot --&gt; E["Parse &amp; Replay Event Log"]
    E --&gt; F["Compare Token REMs with Replayed REMs"]
    F --&gt; G["Extract &amp; Verify Firmware States"]
    G --&gt; D
</code></pre> <p>In this process, the device certificate is verified using the root and subordinate certificates. The integrity of the attestation token is then validated against the device certificate. For grub boot, the following steps are done with the support of event logs and reference values of measurements. Please refer to <code class="language-plaintext highlighter-rouge">verify_token</code> function in <a href="https://gitee.com/openeuler/virtCCA_sdk/blob/master/attestation/samples/src/client.c">client.c</a> to see detailed codes.</p> ]]></content><author><name></name></author><category term="cc"/><category term="virtcca"/><category term="measurement"/><category term="attestation"/><summary type="html"><![CDATA[Our solution to establish trust for confidential VMs booting via firmware.]]></summary></entry><entry><title type="html">Measured boot in Intel TDX’s grub boot</title><link href="https://mahaocheng.me/blog/2025/tdx-measure-boot/" rel="alternate" type="text/html" title="Measured boot in Intel TDX’s grub boot"/><published>2025-01-12T00:00:00+00:00</published><updated>2025-01-12T00:00:00+00:00</updated><id>https://mahaocheng.me/blog/2025/tdx-measure-boot</id><content type="html" xml:base="https://mahaocheng.me/blog/2025/tdx-measure-boot/"><![CDATA[<p>Intel Trust Domain Extension (TDX) allows people to deploy hardware-isolated virtual machines (VMs) called trust domains (TDs). A TD VM is isolated from the virtual machine manager (VMM), hypervisor, and other non-TD software on the host platform. The entire memory contents of a TD is encrypted using a multiple-key encryption method. Intel TDX excludes the host platform from the TD’s trusted computing base (TCB).</p> <p>Intel TDX workloads are primarily VM images that tenants want to run as TDs in a cloud environment. Special Open Virtual Machine Firmware (OVMF) supplied by the CSP is required to run a VM in a TD, such as TDX Virtual Firmware (TDVF). TDVF is an EDK2 based project to enable UEFI support for TDX based Virtual Machines. It provides the capability to launch a TD. TDVF allows two configurations with different features, please see <a href="#jumpA">Appendix: TDVF Configurations</a> from <a href="https://github.com/tianocore/edk2/blob/master/OvmfPkg/IntelTdx/README.md">Configurations and Features</a>.</p> <p>During TD boot, the hash-chained measurement on TCB will be extended to some secure registers (also known as measured boot). The values from several secure registers construct to a report and are finally signed to be a quote by an attestation key. Before providing data to the workload, a relying party uses attestation to verify that the software is running within a TD on a genuine Intel TDX system and at the specified security level.</p> <p><em>NOTE: Here TCB refers to all of a system’s hardware, firmware, and software components that provide a secure environment, including hardware information such as CPU, SEAM firmware, and guest components such as OVMF, bootloader (shim/grub), and kernel.</em></p> <p><strong>The above is a brief description of Intel TDX. In the upcoming series of articles, we will focus on TD’s measured boot and attestation.</strong></p> <h2 id="td-boot-types">TD Boot Types</h2> <p>The following diagram illustrates the TD boot type and boot process.</p> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-01-12-tdx-measure-boot/td_guest_boot_process.png" sizes="95vw"/> <img src="/assets/img/2025-01-12-tdx-measure-boot/td_guest_boot_process.png" class="img-fluid rounded z-depth-0 mx-auto d-block" width="100%" height="auto" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <div class="caption">     Figure 1. TD Guest Boot Process </div> <p><strong>Direct boot</strong> is a boot process where the system boots directly into the OS without an intermediate boot loader. It can also be referred to as direct kernel boot with firmware, in which firmware loads kernel and initrd through the FwCfg device provided by Qemu.</p> <p><strong>Grub boot</strong> involves using the Grub bootloader, which provides advanced boot menu options, allowing you to select different operating systems and customize boot configurations. It can also be referred to as firmware-only boot, in which firmware launches a bootloader from a disk image.</p> <p>The detailed boot flow for different TD boot methods can be found in Figure 2.</p> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-01-12-tdx-measure-boot/detailed_flow_for_different_td_boot.png" sizes="95vw"/> <img src="/assets/img/2025-01-12-tdx-measure-boot/detailed_flow_for_different_td_boot.png" class="img-fluid rounded z-depth-0 mx-auto d-block" width="100%" height="auto" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <div class="caption">     Figure 2. Detailed Flow for Different TD Boot </div> <p><strong>Today we will be diving into Measured Boot in Grub Boot.</strong></p> <p>In the virtual firmware, i.e., OVMF, the image handler <code class="language-plaintext highlighter-rouge">DxeTpmMeasureBootHandler</code> will be triggered when loading EFI image via <code class="language-plaintext highlighter-rouge">CoreLoadImageCommon()</code>. The <code class="language-plaintext highlighter-rouge">DxeTpmMeasureBootHandler</code> measures the objects like FV, QEMU CFG, VMM Hob, Variable into measurement registers (MRs). Then in boot loader ShimX64.efi, <code class="language-plaintext highlighter-rouge">TpmMeasureVariable()</code> measures the secure boot’s certificates into MRs. If secure boot is not enabled, ShimX64.efi may be absent from the VM image. Finally, boot loader GrubX64.efi measures kernel binary and cmdline, initrd binary, and grub’s module into MRs.</p> <p>Yes, the process here is draws on the TCG trusted boot chain. The difference is that it does not trust the hypervisor and avoids using mutable non-volatile storage (causing MR change). Futhermore, its trust chain can trace back to the TDX enable hardware.</p> <h2 id="uefi-boot-sequence">UEFI Boot Sequence</h2> <p>UEFI allows the extension of platform firmware by loading UEFI driver and UEFI application images. When UEFI drivers and UEFI applications are loaded they have access to all UEFI-defined runtime and boot services. See the Booting Sequence Figure 3 below.</p> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-01-12-tdx-measure-boot/uefi_booting_sequence.png" sizes="95vw"/> <img src="/assets/img/2025-01-12-tdx-measure-boot/uefi_booting_sequence.png" class="img-fluid rounded z-depth-0 mx-auto d-block" width="100%" height="auto" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <div class="caption">     Figure 3. UEFI Booting Sequence </div> <p>UEFI allows the consolidation of boot menus from the OS loader and platform firmware into a single platform firmware menu. These platform firmware menus will allow the selection of any UEFI OS loader from any partition on any boot medium that is supported by UEFI boot services.</p> <p>The OS loader operates as a UEFI application, utilizing UEFI services via Boot Services (BS) and Runtime Services (RT). It then invokes <code class="language-plaintext highlighter-rouge">ExitBootServices()</code> to terminate BS and release its resources, with only RT remaining available to the OS.</p> <p>A detailed introduction to UEFI boot phases refers to <a href="#jumpB">Appendix: UEFI Boot Phase</a> from <a href="https://secret.club/2020/05/26/introduction-to-uefi-part-1.html#uefi-boot-phases">UEFI boot phases</a>.</p> <h2 id="measured-boot-component">Measured Boot Component</h2> <p>See Figure 4, the pre-boot environment before the kernel includes the TDVF/OVMF phase and the bootloader phase (shim and grub). The whole boot chain will be measured into Runtime Measurement Register (RTMR) via <code class="language-plaintext highlighter-rouge">EFI_CC_MEASUREMENT_PROTOCOL</code>.</p> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-01-12-tdx-measure-boot/td_measurement_process.png" sizes="95vw"/> <img src="/assets/img/2025-01-12-tdx-measure-boot/td_measurement_process.png" class="img-fluid rounded z-depth-0 mx-auto d-block" width="100%" height="auto" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <div class="caption">     Figure 4. TD Measurement Process </div> <p>Similar to the TCG event log, <code class="language-plaintext highlighter-rouge">EFI_CC_MEASUREMENT_PROTOCOL</code> logs the events into confidential computing event log (CCEL) ACPI table and the measurement hash is extended to the corresponding RTMR register. The event logs in CCEL table can be replayed within a TD guest to verify the RTMR value.</p> <p>The Measured Boot Component in EDK2 is as follows.</p> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-01-12-tdx-measure-boot/measured_boot_component_in_edk2.png" sizes="95vw"/> <img src="/assets/img/2025-01-12-tdx-measure-boot/measured_boot_component_in_edk2.png" class="img-fluid rounded z-depth-0 mx-auto d-block" width="100%" height="auto" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <div class="caption">     Figure 5. Measured Boot Component in EDK2 </div> <p>The <a href="https://github.com/tianocore/edk2/tree/master/OvmfPkg/IntelTdx/TdxHelperLib"><code class="language-plaintext highlighter-rouge">SecTdxHelperLib</code></a> library provides measurement functions in SEC phase. The <a href="https://github.com/tianocore/edk2/blob/master/MdePkg/Include/Protocol/CcMeasurement.h"><code class="language-plaintext highlighter-rouge">EFI_CC_MEASUREMENT_PROTOCOL</code></a> protocol abstracts the confidential computing (CC) measurement operation in UEFI guest environment. The <a href="https://github.com/tianocore/edk2/blob/master/OvmfPkg/Tcg/TdTcg2Dxe/TdTcg2Dxe.c">TdTcg2Dxe.c</a> DXE driver handles the DXE phase measurement. The <a href="https://github.com/tianocore/edk2/tree/master/SecurityPkg/Library/DxeTpm2MeasureBootLib"><code class="language-plaintext highlighter-rouge">DxeTpm2MeasureBootLib</code></a> library handles the PE image measurements and GPT measurement. All event type definition can be found at <a href="https://github.com/tianocore/edk2/blob/master/MdePkg/Include/IndustryStandard/UefiTcgPlatform.h"><code class="language-plaintext highlighter-rouge">UefiTcgPlatform.h</code></a>.</p> <p>Here we give a description of <code class="language-plaintext highlighter-rouge">EFI_CC_MEASUREMENT_PROTOCOL</code> from <a href="https://uefi.org/specs/UEFI/2.10/38_Confidential_Computing.html#">Confidential Computing in UEFI Specification</a>.</p> <p>If a virtual firmware with CC capability supports measurement, the virtual firmware should produce <code class="language-plaintext highlighter-rouge">EFI_CC_MEASUREMENT_PROTOCOL</code> with new GUID <code class="language-plaintext highlighter-rouge">EFI_CC_MEASUREMENT_PROTOCOL_GUID</code> to report event log and provide hash capability.</p> <div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="cp">#define EFI_CC_MEASUREMENT_PROTOCOL_GUID  \
  { 0x96751a3d, 0x72f4, 0x41a6, { 0xa7, 0x94, 0xed, 0x5d, 0x0e, 0x67, 0xae, 0x6b }}
</span><span class="k">extern</span> <span class="n">EFI_GUID</span>  <span class="n">gEfiCcMeasurementProtocolGuid</span><span class="p">;</span>

<span class="cp"># Protocol Interface Structure
</span><span class="k">typedef</span> <span class="k">struct</span> <span class="n">_EFI_CC_MEASUREMENT_PROTOCOL</span> <span class="p">{</span>
  <span class="n">EFI_CC_GET_CAPABILITY</span>          <span class="n">GetCapability</span><span class="p">;</span>
  <span class="n">EFI_CC_GET_EVENT_LOG</span>           <span class="n">GetEventLog</span><span class="p">;</span>
  <span class="n">EFI_CC_HASH_LOG_EXTEND_EVENT</span>   <span class="n">HashLogExtendEvent</span><span class="p">;</span>
  <span class="n">EFI_CC_MAP_PCR_TO_MR_INDEX</span>     <span class="n">MapPcrToMrIndex</span><span class="p">;</span>
<span class="p">}</span> <span class="n">EFI_CC_MEASUREMENT_PROTOCOL</span><span class="p">;</span>
</code></pre></div></div> <p>This protocol defines four parameters in the above interface structure, including:</p> <ul> <li>GetCapability provides protocol capability information and state information.</li> <li>GetEventLog allows a caller to retrieve the address of a given event log and its last entry.</li> <li>HashLogExtendEvent provides callers with an opportunity to extend and optionally log events without requiring knowledge of actual CC command.</li> <li>MapPcrToMrIndex provides callers information on TPM PCR to CC MR mapping.</li> </ul> <p><strong>Mapping for Intel TDX</strong></p> <p>The following table shows the TPM Platform Configuration Register (PCR) index mapping and CC event log MR index interpretation for Intel TDX, where MRTD means Trust Domain Measurement Register and RTMR means Runtime Measurement Register. There certainly are fewer TD MRs than TPM PCRs. They are typically mapped as below:</p> <table> <thead> <tr> <th>TPM PCR Index</th> <th>Typical Usage of Measurement Registers</th> <th>TDX MR Index</th> </tr> </thead> <tbody> <tr> <td>0</td> <td>FirmwareCode (BFV, including init page table)</td> <td>MRTD</td> </tr> <tr> <td>1</td> <td>FirmwareData (CFV, TD Hob, ACPI Table, Boot Variable)</td> <td>RTMR[0]</td> </tr> <tr> <td>2</td> <td>Option ROM code</td> <td>RTMR[1]</td> </tr> <tr> <td>3</td> <td>Option ROM code</td> <td>RTMR[1]</td> </tr> <tr> <td>4</td> <td>OS loader code</td> <td>RTMR[1]</td> </tr> <tr> <td>5</td> <td>GUID partition table (GPT)</td> <td>RTMR[1]</td> </tr> <tr> <td>6</td> <td>N/A</td> <td>N/A</td> </tr> <tr> <td>7</td> <td>Secure Boot Configuration</td> <td>RTMR[0]</td> </tr> <tr> <td>8~15</td> <td>TD OS measurement</td> <td>RTMR[2]</td> </tr> </tbody> </table> <p><em>NOTE: RTMR[3] is reserved for special usage, such as virtual TPM. Users have the flexibility to utilize RTMR[3] if it is not required for these specialized purposes.</em></p> <p>The typical usage of MRTD and RTMR is shown below, more detailes could be found in <a href="https://cdrdv2.intel.com/v1/dl/getContent/733585">8.1 Measurement Register Usage in TD</a>.</p> <ul> <li>MRTD is for the TDVF code (match PCR[0]).</li> <li>RTMR[0] is for the TDVF configuration (match PCR[1,7]). The usage should follow TCG Platform Firmware Profile (PFP) specification.</li> <li>RTMR[1] is for the TDVF loaded component, such as OS loader (match PCR[4,5]). The usage should follow TCG Platform Firmware Profile (PFP) specification.</li> <li>RTMR[2] is for the OS component, such as OS kernel, initrd, and application (match PCR[8~15]). The usage is OS dependent.</li> <li>RTMR[3] is reserved for special usage only.</li> </ul> <h2 id="measured-boot-flow">Measured Boot Flow</h2> <p>In general, the transitions (dotted line in Booting Sequence figure) where events are measured. Hence a trusted chain, i.e., virtual firmware -&gt; bootloaders -&gt; OS -&gt; applications will be built.</p> <p><strong>Measure TdHob and Configuration FV (Cfv)</strong></p> <p><a href="https://cdrdv2.intel.com/v1/dl/getContent/733585">4.2 TD Hand-Off Block (HOB)</a> and <a href="https://cdrdv2.intel.com/v1/dl/getContent/733585">3.2 Configuration Firmware Volume (CFV)</a> are external data provided by Host VMM. These are not trusted in TD guest. So they should be validated, measured and extended to TD RTMR registers. In the meantime 2 <code class="language-plaintext highlighter-rouge">EFI_CC_EVENT_HOB</code> are created. These 2 GUIDed HOBs carry the hash value of TdHobList and Configuration FV. In DXE phase <code class="language-plaintext highlighter-rouge">EFI_CC_EVENT</code> can be created based on these 2 GUIDed HOBs.</p> <p>Configuration Firmware Volume includes all the provisioned data. This region is read only. One possible usage is to provide UEFI Secure Boot Variable content in this region, such as PK, KEK, db, dbx.</p> <p>The TD HOB list is used to pass the information from VMM to TDVF. The TD HOB must include PHIT HOB, Resource Descriptor HOB. Other HOBs are optional.</p> <ul> <li>The TD HOB must include PHIT HOB as the first HOB. EfiMemoryTop, EfiMemoryBottom, EfiFreeMemoryTop, and EfiFreeMemoryBottom shall be zero.</li> <li>The TD HOB must include at least one Resource Description HOB to declare the physical memory resource.</li> </ul> <p><strong><em>0.</em></strong> <code class="language-plaintext highlighter-rouge">SecTdxHelperLib</code> is the SEC instance of TdxHelperLib. It implements the following functions for tdx in SEC phase:</p> <ul> <li><code class="language-plaintext highlighter-rouge">TdxHelperMeasureTdHob</code> measure/extend TdHob and store the measurement value in workarea.</li> <li><code class="language-plaintext highlighter-rouge">TdxHelperMeasureCfvImage</code> measure/extend the Configuration FV image and store the measurement value in workarea.</li> <li><code class="language-plaintext highlighter-rouge">TdxHelperBuildGuidHobForTdxMeasurement</code> builds GuidHob for TDX measurement.</li> </ul> <p><strong>Measure Secure Boot Policy to PCR[7]/RTMR[0]</strong></p> <p><em>1.</em> UEFI Debug Mode.</p> <p>If a platform provides a firmware debugger mode, then the platform shall measure “UEFI Debug Mode” string with <code class="language-plaintext highlighter-rouge">EV_EFI_ACTION</code>. This logic is done at TdTcg2Dxe.c <code class="language-plaintext highlighter-rouge">MeasureSecureBootPolicy()</code>, based upon <a href="https://github.com/tianocore/edk2/blob/master/SecurityPkg/SecurityPkg.dec"><code class="language-plaintext highlighter-rouge">PcdFirmwareDebuggerInitialized</code></a>.</p> <p><em>2.</em> The contents of the <code class="language-plaintext highlighter-rouge">SecureBoot</code> variable.</p> <p><em>3.</em> The contents of the <code class="language-plaintext highlighter-rouge">PK</code> variable.</p> <p><em>4.</em> The contents of the <code class="language-plaintext highlighter-rouge">KEK</code> variable.</p> <p><em>5.</em> The contents of the <code class="language-plaintext highlighter-rouge">EFI_IMAGE_SECURITY_DATABASE</code> variable (the DB).</p> <p><em>6.</em> The contents of the <code class="language-plaintext highlighter-rouge">EFI_IMAGE_SECURITY_DATABASE1</code> variable (the DBX).</p> <p><em>7.</em> The contents of the <code class="language-plaintext highlighter-rouge">EFI_IMAGE_SECURITY_DATABASE2</code> (the DBT) variable, if present and not empty.</p> <p>The UEFI secure boot related variables – “SecureBoot”, “PK”, “KEK”, “db”, and “dbx” are unconditionally measured by TdTcg2Dxe.c <code class="language-plaintext highlighter-rouge">ReadAndMeasureSecureVariable()</code>. The event type is <a href="https://github.com/tianocore/edk2/blob/master/MdePkg/Include/IndustryStandard/UefiTcgPlatform.h"><code class="language-plaintext highlighter-rouge">EV_EFI_VARIABLE_DRIVER_CONFIG</code></a>. If they are not present, a zero size UEFI variable entry will be measured. The “dbt” and “dbr” variables are conditionally measured only if they are present by the routine <code class="language-plaintext highlighter-rouge">MeasureAllSecureVariables()</code>.</p> <p><em>8.</em> Separator.</p> <p><a href="https://github.com/tianocore/edk2/blob/master/MdePkg/Include/IndustryStandard/UefiTcgPlatform.h"><code class="language-plaintext highlighter-rouge">EV_SEPARATOR</code></a> for PCR7 is handled in TdTcg2Dxe.c <code class="language-plaintext highlighter-rouge">MeasureSecureBootPolicy()</code> when the UEFI variable is ready. It is just after <code class="language-plaintext highlighter-rouge">MeasureAllSecureVariables()</code>. It is earlier than the <code class="language-plaintext highlighter-rouge">ReadyToBoot</code> event signal. The reason is that the PCR7 <code class="language-plaintext highlighter-rouge">EV_SEPARATOR</code> must be between SecureBootPolicy (Configure) and and ImageVerification (Authority).</p> <p><strong>Measure Boot Variable to PCR[1]/RTMR[0]</strong></p> <p><em>9.</em> The UEFI BootOrder Variable and the Boot#### variables (just device paths).</p> <p>The UEFI boot related variables, such as “BootOrder.” and “Boot####” are measured by TdTcg2Dxe.c <code class="language-plaintext highlighter-rouge">ReadAndMeasureBootVariable()</code>. The event type is <a href="https://github.com/tianocore/edk2/blob/master/MdePkg/Include/IndustryStandard/UefiTcgPlatform.h"><code class="language-plaintext highlighter-rouge">EV_EFI_VARIABLE_BOOT</code></a>. These variables are measured if they are present in <code class="language-plaintext highlighter-rouge">MeasureAllBootVariables()</code>.</p> <p><strong>Upon selecting a boot device,</strong></p> <p><em>10.</em> The boot attempt action “Calling EFI Application from Boot Option”, this means Boot Manager attempting to execute code from a Boot Option (<strong>PCR[4]/RTMR[1]</strong>).</p> <p>The boot attempt action is measured by TdTcg2Dxe.c <code class="language-plaintext highlighter-rouge">OnReadyToBoot()</code>. Before invoking a boot option, it measures the action "Calling EFI Application from Boot Option". After the boot option returns, it measures the action "Returning from EFI Application from Boot Option".</p> <p><em>11.</em> Separator, Draw a line between leaving pre-boot env and entering post-boot env (<strong>PCR[0~6]/RTMR[1]</strong>).</p> <p><em>12.</em> <strong>[Optional] If UEFI Secure Boot is enabled,</strong> measure the entry in the <code class="language-plaintext highlighter-rouge">EFI_IMAGE_SECURITY_DATABASE</code> that was used to validate the UEFI image (<strong>PCR[7]/RTMR[0]</strong>).</p> <p>When UEFI secure boot is enabled, the <a href="https://github.com/tianocore/edk2/tree/master/SecurityPkg/Library/DxeImageVerificationLib"><code class="language-plaintext highlighter-rouge">DxeImageVerificationLib</code></a> verifies the PE image signature based upon the <a href="https://github.com/tianocore/edk2/blob/master/MdePkg/Include/Guid/ImageAuthentication.h"><code class="language-plaintext highlighter-rouge">EFI_SIGNATURE_DATA</code></a> in the <a href="https://github.com/tianocore/edk2/blob/master/MdePkg/Include/Guid/ImageAuthentication.h"><code class="language-plaintext highlighter-rouge">EFI_SIGNATURE_LIST</code></a> of an image signature database. If an <code class="language-plaintext highlighter-rouge">EFI_SIGNATURE_DATA</code> is used to verify the image, then this <code class="language-plaintext highlighter-rouge">EFI_SIGNATURE_DATA</code> will be measured with <a href="https://github.com/tianocore/edk2/blob/master/MdePkg/Include/IndustryStandard/UefiTcgPlatform.h"><code class="language-plaintext highlighter-rouge">EV_EFI_VARIABLE_AUTHORITY</code></a> in <code class="language-plaintext highlighter-rouge">MeasureVariable()</code> of <a href="https://github.com/tianocore/edk2/blob/master/SecurityPkg/Library/DxeImageVerificationLib/Measurement.c">Measurement.c</a>.</p> <p><em>13.</em> The GUID Partition Table (GPT) disk geometry (<strong>PCR[5]/RTMR[1]</strong>).</p> <p>When a system boots a boot option in a GUID-named partition of the disk, the GUID partition table (GPT) disk geometry needs to be measured. It is done by <a href="https://github.com/tianocore/edk2/blob/master/SecurityPkg/Library/DxeTpm2MeasureBootLib/DxeTpm2MeasureBootLib.c">DxeTpm2MeasureBootLib.c</a> <code class="language-plaintext highlighter-rouge">Tcg2MeasureGptTable()</code> in <code class="language-plaintext highlighter-rouge">DxeTpm2MeasureBootHandler()</code>.</p> <p><em>14.</em> The selected UEFI application code PE/COFF image, i.e., OS loader (<strong>PCR[4]/RTMR[1]</strong>).</p> <p>A third party UEFI application, such as a UEFI shell utility, a standard OS loader or an OEM boot option, is measured by DxeTpm2MeasureBootLib.c <code class="language-plaintext highlighter-rouge">Tcg2MeasurePeImage()</code> in <code class="language-plaintext highlighter-rouge">DxeTpm2MeasureBootHandler()</code>. The event type is <a href="https://github.com/tianocore/edk2/blob/master/MdePkg/Include/IndustryStandard/UefiTcgPlatform.h"><code class="language-plaintext highlighter-rouge">EV_EFI_BOOT_SERVICES_APPLICATION</code></a>. If a UEFI application is an FV which is dispatched in the DXE phase, it is also measured to PCR4 irrespective of whether the FV is measured or unmeasured.</p> <p><strong>Then OS loader, i.e., <a href="https://git.savannah.gnu.org/cgit/grub.git/">Grub2</a> extends the trusted boot chain from virtual firmware into the OS.</strong></p> <p><em>NOTE: Here we do not concern <a href="https://github.com/rhboot/shim">Shim</a> component since we only focus on measured boot. Shim is used to extend the UEFI secure boot concept to Linux.</em></p> <p><em>15.</em> Grub2 measures configuration file (e.g., grub.cfg), grub commands, kernel binary, kernel commands and initrd binary (<strong>PCR[8, 9]/RTMR[2]</strong>). PCR[8] is for the command line string and PCR[9] is for a file binary, as shown in the following table.</p> <p>To support measurements on confidential computing platforms, two patches have been upstreamed, including:</p> <ul> <li><a href="https://git.savannah.gnu.org/cgit/grub.git/commit/?id=4c76565b6cb885b7e144dc27f3612066844e2d19">efi/tpm: Add EFI_CC_MEASUREMENT_PROTOCOL support</a></li> <li><a href="https://git.savannah.gnu.org/cgit/grub.git/commit/?id=86df79275d065d87f4de5c97e456973e8b4a649c">commands/efi/tpm: Re-enable measurements on confidential computing platforms</a></li> </ul> <table> <thead> <tr> <th>PCR Index</th> <th>PCR Usage</th> </tr> </thead> <tbody> <tr> <td>8</td> <td>Grub command line: All executed commands (including those from configuration files) will be logged and measured as entered with a prefix of “grub cmd:”</td> </tr> <tr> <td> </td> <td>Kernel command line: Any command line passed to a kernel will be logged and measured as entered with a prefix of “kernel cmdline:”</td> </tr> <tr> <td> </td> <td>Module command line: Any command line passed to a kernel module will be logged and measured as entered with a prefix of “module cmdline:”</td> </tr> <tr> <td>9</td> <td>Files: Any file read by GRUB will be logged and measured with a descriptive text corresponding to the filename.</td> </tr> </tbody> </table> <p><a href="https://github.com/rhboot/grub2/blob/master/grub-core/commands/tpm.c">tpm.c</a> registers <code class="language-plaintext highlighter-rouge">grub_tpm_verify_string()</code> and <code class="language-plaintext highlighter-rouge">grub_tpm_verify_write()</code> to a grub_file_verifier structure. They will be called by <code class="language-plaintext highlighter-rouge">grub_verify_string()</code> and <code class="language-plaintext highlighter-rouge">grub_verifiers_open()</code> in <a href="https://github.com/rhboot/grub2/blob/master/grub-core/commands/verifiers.c">verifiers.c</a>.</p> <p>when grub2 executes a command line such as <code class="language-plaintext highlighter-rouge">GRUB_VERIFY_MODULE_CMDLINE</code>, <code class="language-plaintext highlighter-rouge">GRUB_VERIFY_KERNEL_CMDLINE</code>, <code class="language-plaintext highlighter-rouge">GRUB_VERIFY_COMMAND</code> or <code class="language-plaintext highlighter-rouge">grub_create_loader_cmdline()</code> in <a href="https://github.com/rhboot/grub2/blob/master/grub-core/lib/cmdline.c">cmdline.c</a>, <code class="language-plaintext highlighter-rouge">grub_verify_string()</code> is used. Finally, <code class="language-plaintext highlighter-rouge">grub_tpm_verify_string()</code> calls <code class="language-plaintext highlighter-rouge">grub_tpm_measure</code> and then <code class="language-plaintext highlighter-rouge">grub_cc_log_event</code> to measure the string to <strong>PCR[8]/RTMR[2]</strong>.</p> <p><code class="language-plaintext highlighter-rouge">grub_verifiers_open()</code> is registered as one of grub_file_filters in <a href="https://github.com/rhboot/grub2/blob/master/include/grub/file.h"><code class="language-plaintext highlighter-rouge">file.h</code></a>. Whenever grub uses <a href="https://github.com/rhboot/grub2/blob/master/grub-core/kern/file.c">file.c</a> <code class="language-plaintext highlighter-rouge">grub_file_open()</code> this filter is invoked. Finally, <code class="language-plaintext highlighter-rouge">grub_tpm_verify_write()</code> calls <code class="language-plaintext highlighter-rouge">grub_tpm_measure</code> and then <code class="language-plaintext highlighter-rouge">grub_cc_log_event</code> to measure the file binary to <strong>PCR[9]/RTMR[2]</strong>.</p> <p><em>16.</em> The boot attempt action “Exit Boot Services Invocation”, this means Boot Manager has sent the call to UEFI to end Boot Services (<strong>PCR[5]/RTMR[1]</strong>).</p> <p><em>17.</em> The boot attempt action “Exit Boot Services Returned with Success”, this means UEFI successfully existed Boot Services and pre-OS environment has been terminated (<strong>PCR[5]/RTMR[1]</strong>).</p> <p>The ExitBootServices action is measured by TdTcg2Dxe.c. If ExitBootServices succeeds, then <code class="language-plaintext highlighter-rouge">OnExitBootServices()</code> is invoked. If ExitBootServices fails, then <code class="language-plaintext highlighter-rouge">OnExitBootServicesFailed()</code> is invoked.</p> <p><strong>If Security Boot Policy update after initial measurement and before <code class="language-plaintext highlighter-rouge">ExitBootServices()</code> has completed,</strong></p> <p><em>18.</em> The platform MAY be restarted OR the variables MUST be remeasured into (<strong>PCR[7]/RTMR[0]</strong>). Additionally the normal update process for setting any of the defined Secure Boot variables SHOULD occur before the initial measurement in PCR[7] or after the call to <code class="language-plaintext highlighter-rouge">ExitBootServices()</code> has completed.</p> <p>The UEFI secure boot variable update is measured in Variable <a href="https://github.com/tianocore/edk2/tree/master/MdeModulePkg/Universal/Variable/RuntimeDxe"><code class="language-plaintext highlighter-rouge">RuntimeDxe</code></a>. If any of the above secure boot related variables are updated, then <a href="https://github.com/tianocore/edk2/blob/master/MdeModulePkg/Universal/Variable/RuntimeDxe/Measurement.c">Measurement.c</a> <code class="language-plaintext highlighter-rouge">MeasureVariable()</code> will measure the new data with <code class="language-plaintext highlighter-rouge">EV_EFI_VARIABLE_DRIVER_CONFIG</code>.</p> <h2 id="attestation">Attestation</h2> <p>We will analyse how to verify the TD Quote from the perspective of the verifier, without focusing on the Quote generation or interactions with the attester. At a high level, it can be broken down into Quote Verification, Event Log Replay and Event Parsing.</p> <h3 id="quote-verification">Quote Verification</h3> <p>A measured boot root of trust (RoT) can issue a report of the MRs, often called a quote or attestation report. This quote is typically a digitally-signed digest of MRs.</p> <p>A verifier then checks that the digest of MRs are signed by a trustworthy key, the RoT for Reporting (RTR). This RTR, aka attestation key, is typically a certified key that signs a report of the MRs. This certification is known as an Endorsement in the IETF RATS Architecture. More details about quote verification could be found in <a href="https://github.com/intel/SGXDataCenterAttestationPrimitives">Intel SGX-based Data Center Attestation Primitives (DCAP)</a>.</p> <h3 id="event-log-replay">Event Log Replay</h3> <p>Event log replay involves deserializing a raw event log and using the events to recalculate all of the measurement registers. Each event contains a digest and a measurement register index. The verifier will create simulated measurement registers and, for each event, extend the event digest into its corresponding simulated register. At the end, the verifier compares the simulated register values against the actual quoted measurement register values from the first step.</p> <p>Intel provides a Python library called <a href="https://github.com/canonical/tdx/tree/main/tests/lib/tdx-tools/src/tdxtools">tdx-tools</a> to verify TD measurements. It consists of the following three steps. For the step-by-step flow, please refer to class <code class="language-plaintext highlighter-rouge">VerifyActor</code> defined in tdx-tools.</p> <ul> <li>Get TD event log from CCEL ACPI table.</li> <li>Get TDREPORT via Linux attestation driver.</li> <li>Compare RTMR value from TDREPORT and RTMR value replayed via event log.</li> </ul> <p>The two values are expected to be identical, which means the measured contents are not tampered with.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">VerifyActor</span><span class="p">:</span>
    <span class="sh">"""</span><span class="s">
    Actor to verify the RTMR
    </span><span class="sh">"""</span>

    <span class="k">def</span> <span class="nf">_verify_single_rtmr</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">rtmr_index</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">rtmr_value_1</span><span class="p">:</span> <span class="n">RTMR</span><span class="p">,</span>
        <span class="n">rtmr_value_2</span><span class="p">:</span> <span class="n">RTMR</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="bp">None</span><span class="p">:</span>

        <span class="k">if</span> <span class="n">rtmr_value_1</span> <span class="o">==</span> <span class="n">rtmr_value_2</span><span class="p">:</span>
            <span class="n">LOG</span><span class="p">.</span><span class="nf">info</span><span class="p">(</span><span class="sh">"</span><span class="s">RTMR[%d] passed the verification.</span><span class="sh">"</span><span class="p">,</span> <span class="n">rtmr_index</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">LOG</span><span class="p">.</span><span class="nf">error</span><span class="p">(</span><span class="sh">"</span><span class="s">RTMR[%d] did not pass the verification</span><span class="sh">"</span><span class="p">,</span> <span class="n">rtmr_index</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">verify_rtmr</span><span class="p">(</span><span class="n">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="bp">None</span><span class="p">:</span>
        <span class="sh">"""</span><span class="s">
        Get TD report and RTMR replayed by event log to do verification.
        </span><span class="sh">"""</span>
        <span class="c1"># 1. Read CCEL from ACPI table at /sys/firmware/acpi/tables/CCEL
</span>        <span class="n">ccelobj</span> <span class="o">=</span> <span class="n">CCEL</span><span class="p">.</span><span class="nf">create_from_acpi_file</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">ccelobj</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
            <span class="k">return</span>

        <span class="c1"># 2. Get the start address and length for event log area
</span>        <span class="n">td_event_log_actor</span> <span class="o">=</span> <span class="nc">TDEventLogActor</span><span class="p">(</span>
            <span class="n">ccelobj</span><span class="p">.</span><span class="n">log_area_start_address</span><span class="p">,</span>
            <span class="n">ccelobj</span><span class="p">.</span><span class="n">log_area_minimum_length</span><span class="p">)</span>

        <span class="c1"># 3. Collect event log and replay the RTMR value according to event log
</span>        <span class="n">td_event_log_actor</span><span class="p">.</span><span class="nf">replay</span><span class="p">()</span>

        <span class="c1"># 4. Read TD REPORT via TDCALL.GET_TDREPORT
</span>        <span class="n">td_report</span> <span class="o">=</span> <span class="n">TdReport</span><span class="p">.</span><span class="nf">get_td_report</span><span class="p">()</span>

        <span class="c1"># 5. Verify individual RTMR value from TDREPORT and recalculated from
</span>        <span class="c1">#    event log
</span>        <span class="n">self</span><span class="p">.</span><span class="nf">_verify_single_rtmr</span><span class="p">(</span>
            <span class="mi">0</span><span class="p">,</span>
            <span class="n">td_event_log_actor</span><span class="p">.</span><span class="nf">get_rtmr_by_index</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span>
            <span class="nc">RTMR</span><span class="p">(</span><span class="nf">bytearray</span><span class="p">(</span><span class="n">td_report</span><span class="p">.</span><span class="n">td_info</span><span class="p">.</span><span class="n">rtmr_0</span><span class="p">)))</span>

        <span class="n">self</span><span class="p">.</span><span class="nf">_verify_single_rtmr</span><span class="p">(</span>
            <span class="mi">1</span><span class="p">,</span>
            <span class="n">td_event_log_actor</span><span class="p">.</span><span class="nf">get_rtmr_by_index</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span>
            <span class="nc">RTMR</span><span class="p">(</span><span class="nf">bytearray</span><span class="p">(</span><span class="n">td_report</span><span class="p">.</span><span class="n">td_info</span><span class="p">.</span><span class="n">rtmr_1</span><span class="p">)))</span>

        <span class="n">self</span><span class="p">.</span><span class="nf">_verify_single_rtmr</span><span class="p">(</span>
            <span class="mi">2</span><span class="p">,</span>
            <span class="n">td_event_log_actor</span><span class="p">.</span><span class="nf">get_rtmr_by_index</span><span class="p">(</span><span class="mi">2</span><span class="p">),</span>
            <span class="nc">RTMR</span><span class="p">(</span><span class="nf">bytearray</span><span class="p">(</span><span class="n">td_report</span><span class="p">.</span><span class="n">td_info</span><span class="p">.</span><span class="n">rtmr_2</span><span class="p">)))</span>

        <span class="n">self</span><span class="p">.</span><span class="nf">_verify_single_rtmr</span><span class="p">(</span>
            <span class="mi">3</span><span class="p">,</span>
            <span class="n">td_event_log_actor</span><span class="p">.</span><span class="nf">get_rtmr_by_index</span><span class="p">(</span><span class="mi">3</span><span class="p">),</span>
            <span class="nc">RTMR</span><span class="p">(</span><span class="nf">bytearray</span><span class="p">(</span><span class="n">td_report</span><span class="p">.</span><span class="n">td_info</span><span class="p">.</span><span class="n">rtmr_3</span><span class="p">)))</span>
</code></pre></div></div> <h3 id="event-parsing">Event Parsing</h3> <p>Event parsing is the process of pulling information from the events. The verifier uses the output to make verification decisions against the appraisal policy, endorsements, and reference values.</p> <p>In <a href="https://github.com/google/go-eventlog">go-eventlog</a>, <code class="language-plaintext highlighter-rouge">ReplayAndExtract</code> parses a CC event log and replays the parsed event log against the RTMR bank specified by hash (the second step). It then extracts event info from the verified log into a FirmwareLogState. In this FirmwareLogState, includes details about the firmware, secure boot configuration, bootloaders (such as grub) and kernel (also includes command line and initramfs).</p> <div class="language-go highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">// FirmwareLogState extracts event info from a verified TCG PC Client event</span>
<span class="c">// log into a FirmwareLogState.</span>
<span class="c">//</span>
<span class="c">// It is the caller's responsibility to ensure that the passed events have</span>
<span class="c">// been replayed (e.g., using `tcg.ParseAndReplay`) against a verified measurement</span>
<span class="c">// register bank.</span>
<span class="k">func</span> <span class="n">FirmwareLogState</span><span class="p">(</span><span class="n">events</span> <span class="p">[]</span><span class="n">tcg</span><span class="o">.</span><span class="n">Event</span><span class="p">,</span> <span class="n">hash</span> <span class="n">crypto</span><span class="o">.</span><span class="n">Hash</span><span class="p">,</span> <span class="n">registerCfg</span> <span class="n">registerConfig</span><span class="p">,</span> <span class="n">opts</span> <span class="n">Opts</span><span class="p">)</span> <span class="p">(</span><span class="o">*</span><span class="n">pb</span><span class="o">.</span><span class="n">FirmwareLogState</span><span class="p">,</span> <span class="kt">error</span><span class="p">)</span> <span class="p">{</span>
	<span class="k">var</span> <span class="n">joined</span> <span class="kt">error</span>
	<span class="n">tcgHash</span><span class="p">,</span> <span class="n">err</span> <span class="o">:=</span> <span class="n">tpm2</span><span class="o">.</span><span class="n">HashToAlgorithm</span><span class="p">(</span><span class="n">hash</span><span class="p">)</span>
	<span class="k">if</span> <span class="n">err</span> <span class="o">!=</span> <span class="no">nil</span> <span class="p">{</span>
		<span class="k">return</span> <span class="no">nil</span><span class="p">,</span> <span class="n">err</span>
	<span class="p">}</span>

	<span class="n">platform</span><span class="p">,</span> <span class="n">err</span> <span class="o">:=</span> <span class="n">registerCfg</span><span class="o">.</span><span class="n">PlatformExtracter</span><span class="p">(</span><span class="n">hash</span><span class="p">,</span> <span class="n">events</span><span class="p">)</span>
	<span class="k">if</span> <span class="n">err</span> <span class="o">!=</span> <span class="no">nil</span> <span class="p">{</span>
		<span class="n">joined</span> <span class="o">=</span> <span class="n">errors</span><span class="o">.</span><span class="n">Join</span><span class="p">(</span><span class="n">joined</span><span class="p">,</span> <span class="n">err</span><span class="p">)</span>
	<span class="p">}</span>
	<span class="n">sbState</span><span class="p">,</span> <span class="n">err</span> <span class="o">:=</span> <span class="n">SecureBootState</span><span class="p">(</span><span class="n">events</span><span class="p">,</span> <span class="n">registerCfg</span><span class="p">)</span>
	<span class="k">if</span> <span class="n">err</span> <span class="o">!=</span> <span class="no">nil</span> <span class="p">{</span>
		<span class="n">joined</span> <span class="o">=</span> <span class="n">errors</span><span class="o">.</span><span class="n">Join</span><span class="p">(</span><span class="n">joined</span><span class="p">,</span> <span class="n">err</span><span class="p">)</span>
	<span class="p">}</span>
	<span class="n">efiState</span><span class="p">,</span> <span class="n">err</span> <span class="o">:=</span> <span class="n">EfiState</span><span class="p">(</span><span class="n">hash</span><span class="p">,</span> <span class="n">events</span><span class="p">,</span> <span class="n">registerCfg</span><span class="p">)</span>

	<span class="k">if</span> <span class="n">err</span> <span class="o">!=</span> <span class="no">nil</span> <span class="p">{</span>
		<span class="n">joined</span> <span class="o">=</span> <span class="n">errors</span><span class="o">.</span><span class="n">Join</span><span class="p">(</span><span class="n">joined</span><span class="p">,</span> <span class="n">err</span><span class="p">)</span>
	<span class="p">}</span>

	<span class="k">var</span> <span class="n">grub</span> <span class="o">*</span><span class="n">pb</span><span class="o">.</span><span class="n">GrubState</span>
	<span class="k">var</span> <span class="n">kernel</span> <span class="o">*</span><span class="n">pb</span><span class="o">.</span><span class="n">LinuxKernelState</span>
	<span class="k">if</span> <span class="n">opts</span><span class="o">.</span><span class="n">Loader</span> <span class="o">==</span> <span class="n">GRUB</span> <span class="p">{</span>
		<span class="n">grub</span><span class="p">,</span> <span class="n">err</span> <span class="o">=</span> <span class="n">registerCfg</span><span class="o">.</span><span class="n">GRUBExtracter</span><span class="p">(</span><span class="n">hash</span><span class="p">,</span> <span class="n">events</span><span class="p">)</span>

		<span class="k">if</span> <span class="n">err</span> <span class="o">!=</span> <span class="no">nil</span> <span class="p">{</span>
			<span class="n">joined</span> <span class="o">=</span> <span class="n">errors</span><span class="o">.</span><span class="n">Join</span><span class="p">(</span><span class="n">joined</span><span class="p">,</span> <span class="n">err</span><span class="p">)</span>
		<span class="p">}</span>
		<span class="n">kernel</span><span class="p">,</span> <span class="n">err</span> <span class="o">=</span> <span class="n">LinuxKernelStateFromGRUB</span><span class="p">(</span><span class="n">grub</span><span class="p">)</span>
		<span class="k">if</span> <span class="n">err</span> <span class="o">!=</span> <span class="no">nil</span> <span class="p">{</span>
			<span class="n">joined</span> <span class="o">=</span> <span class="n">errors</span><span class="o">.</span><span class="n">Join</span><span class="p">(</span><span class="n">joined</span><span class="p">,</span> <span class="n">err</span><span class="p">)</span>
		<span class="p">}</span>
	<span class="p">}</span>
	<span class="k">return</span> <span class="o">&amp;</span><span class="n">pb</span><span class="o">.</span><span class="n">FirmwareLogState</span><span class="p">{</span>
		<span class="n">Platform</span><span class="o">:</span>    <span class="n">platform</span><span class="p">,</span>
		<span class="n">SecureBoot</span><span class="o">:</span>  <span class="n">sbState</span><span class="p">,</span>
		<span class="n">Efi</span><span class="o">:</span>         <span class="n">efiState</span><span class="p">,</span>
		<span class="n">RawEvents</span><span class="o">:</span>   <span class="n">tcg</span><span class="o">.</span><span class="n">ConvertToPbEvents</span><span class="p">(</span><span class="n">hash</span><span class="p">,</span> <span class="n">events</span><span class="p">),</span>
		<span class="n">Hash</span><span class="o">:</span>        <span class="n">pb</span><span class="o">.</span><span class="n">HashAlgo</span><span class="p">(</span><span class="n">tcgHash</span><span class="p">),</span>
		<span class="n">Grub</span><span class="o">:</span>        <span class="n">grub</span><span class="p">,</span>
		<span class="n">LinuxKernel</span><span class="o">:</span> <span class="n">kernel</span><span class="p">,</span>
	<span class="p">},</span> <span class="n">joined</span>
<span class="p">}</span>
</code></pre></div></div> <h3 id="reference-measurements">Reference Measurements</h3> <p>The remaining topic is a quite complex challenge: how to generate reference measurements for FirmwareLogState. Now it is still a open issue <a href="https://github.com/canonical/tdx/issues/263">Calculate measurements outside of TDX #263</a> in the tdx repo. Inspired by a tool called <a href="https://github.com/cc-api/cvm-image-rewriter">cvm-image-rewriter</a> in cc-api repo, we may design a plugin to calculate reference measurements of the VM image.</p> <p>The cvm-image-rewriter tool is plugin-based and used to customize the confidential VM guest including guest image, config, OVMF firmware etc. The following table shows some existing plugins.</p> <table> <thead> <tr> <th>Name</th> <th>Descriptions</th> </tr> </thead> <tbody> <tr> <td>01-resize-image</td> <td>Resize the input qcow2 image</td> </tr> <tr> <td>02-motd-welcome</td> <td>Customize the login welcome message</td> </tr> <tr> <td>03-netplan</td> <td>Customize the netplan.yaml</td> </tr> <tr> <td>04-user-authkey</td> <td>Add auth key for user login instead of password</td> </tr> <tr> <td>05-readonly-data</td> <td>Fix some file permission to ready-only</td> </tr> <tr> <td>06-install-tdx-guest-kernel</td> <td>Install MVP TDX guest kernel</td> </tr> <tr> <td>07-device-permission</td> <td>Fix the permission for device node</td> </tr> <tr> <td>08-ccnp-uds-directory-permission</td> <td>Fix the permission for CCNP UDS directory</td> </tr> <tr> <td>60-initrd-update</td> <td>Update the initrd image</td> </tr> <tr> <td>97-sample</td> <td>plugin customization example</td> </tr> <tr> <td>98-ima-enable-simple</td> <td>Enable IMA (Integrity Measurement Architecture) feature</td> </tr> </tbody> </table> <p>After customising the VM image, a plugin (possibly named reference-measurement-calculator) can read the grub and kernel, then compute the digest of the images and configurations. Therefore reference measurements of VM image is obtained for final verification.</p> <p>Next question is how to get reference measurements about the firmware. According to TDVF Binary Layout, we can parse the virtual firmware, locate the BFV and CFV, and then compute their reference measurements. Here, we recommend referring to this tool named <a href="https://github.com/edgelesssys/contrast/blob/main/tools/tdx-measure/tdvf/tdvf.go">tdx-measure</a> in contrast repo.</p> <p>The tool also attempts another attestation approach. It does RTMR precalulation for given firmware and kernel file (see <code class="language-plaintext highlighter-rouge">newRtMrCmd()</code> function), and compare RTMR value from TDREPORT and pre-computed RTMR value. This improves verification efficiency by eliminating the need for the event log. It is important to note that this method is suitable for relatively fixed scenarios. The event logs are still necessary in most scenarios, because firmware, bootloaders, OS and applications are free to append measurements for any event, in any order.</p> <div class="language-go highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">func</span> <span class="n">newRtMrCmd</span><span class="p">()</span> <span class="o">*</span><span class="n">cobra</span><span class="o">.</span><span class="n">Command</span> <span class="p">{</span>
	<span class="n">cmd</span> <span class="o">:=</span> <span class="o">&amp;</span><span class="n">cobra</span><span class="o">.</span><span class="n">Command</span><span class="p">{</span>
		<span class="n">Use</span><span class="o">:</span>   <span class="s">"rtmr -f OVMF.fd -k bzImage [0|1|2|3]"</span><span class="p">,</span>
		<span class="n">Short</span><span class="o">:</span> <span class="s">"calculate the RTMR for a firmware and kernel file"</span><span class="p">,</span>
		<span class="n">Long</span><span class="o">:</span> <span class="s">`Calculate the RTMR for a firmware and kernel file.

		This will parse the firmware according to the TDX Virtual Firmware Design Guide
		and/or hash the kernel and pre-calculate a given RTMR.`</span><span class="p">,</span>
		<span class="n">Args</span><span class="o">:</span>      <span class="n">cobra</span><span class="o">.</span><span class="n">MatchAll</span><span class="p">(</span><span class="n">cobra</span><span class="o">.</span><span class="n">ExactArgs</span><span class="p">(</span><span class="m">1</span><span class="p">),</span> <span class="n">cobra</span><span class="o">.</span><span class="n">OnlyValidArgs</span><span class="p">),</span>
		<span class="n">ValidArgs</span><span class="o">:</span> <span class="p">[]</span><span class="kt">string</span><span class="p">{</span><span class="s">"0"</span><span class="p">,</span> <span class="s">"1"</span><span class="p">,</span> <span class="s">"2"</span><span class="p">,</span> <span class="s">"3"</span><span class="p">},</span>
		<span class="n">RunE</span><span class="o">:</span>      <span class="n">runRtMr</span><span class="p">,</span>
	<span class="p">}</span>
	<span class="n">cmd</span><span class="o">.</span><span class="n">Flags</span><span class="p">()</span><span class="o">.</span><span class="n">StringP</span><span class="p">(</span><span class="s">"firmware"</span><span class="p">,</span> <span class="s">"f"</span><span class="p">,</span> <span class="s">"OVMF.fd"</span><span class="p">,</span> <span class="s">"path to firmware file"</span><span class="p">)</span>
	<span class="k">if</span> <span class="n">err</span> <span class="o">:=</span> <span class="n">cmd</span><span class="o">.</span><span class="n">MarkFlagFilename</span><span class="p">(</span><span class="s">"firmware"</span><span class="p">,</span> <span class="s">"fd"</span><span class="p">);</span> <span class="n">err</span> <span class="o">!=</span> <span class="no">nil</span> <span class="p">{</span>
		<span class="nb">panic</span><span class="p">(</span><span class="n">err</span><span class="p">)</span>
	<span class="p">}</span>
	<span class="n">cmd</span><span class="o">.</span><span class="n">Flags</span><span class="p">()</span><span class="o">.</span><span class="n">StringP</span><span class="p">(</span><span class="s">"kernel"</span><span class="p">,</span> <span class="s">"k"</span><span class="p">,</span> <span class="s">"bzImage"</span><span class="p">,</span> <span class="s">"path to kernel file"</span><span class="p">)</span>
	<span class="k">if</span> <span class="n">err</span> <span class="o">:=</span> <span class="n">cmd</span><span class="o">.</span><span class="n">MarkFlagFilename</span><span class="p">(</span><span class="s">"kernel"</span><span class="p">);</span> <span class="n">err</span> <span class="o">!=</span> <span class="no">nil</span> <span class="p">{</span>
		<span class="nb">panic</span><span class="p">(</span><span class="n">err</span><span class="p">)</span>
	<span class="p">}</span>
	<span class="n">cmd</span><span class="o">.</span><span class="n">Flags</span><span class="p">()</span><span class="o">.</span><span class="n">StringP</span><span class="p">(</span><span class="s">"initrd"</span><span class="p">,</span> <span class="s">"i"</span><span class="p">,</span> <span class="s">"initrd.zst"</span><span class="p">,</span> <span class="s">"path to initrd file"</span><span class="p">)</span>
	<span class="k">if</span> <span class="n">err</span> <span class="o">:=</span> <span class="n">cmd</span><span class="o">.</span><span class="n">MarkFlagFilename</span><span class="p">(</span><span class="s">"initrd"</span><span class="p">);</span> <span class="n">err</span> <span class="o">!=</span> <span class="no">nil</span> <span class="p">{</span>
		<span class="nb">panic</span><span class="p">(</span><span class="n">err</span><span class="p">)</span>
	<span class="p">}</span>
	<span class="n">cmd</span><span class="o">.</span><span class="n">Flags</span><span class="p">()</span><span class="o">.</span><span class="n">StringP</span><span class="p">(</span><span class="s">"cmdline"</span><span class="p">,</span> <span class="s">"c"</span><span class="p">,</span> <span class="s">""</span><span class="p">,</span> <span class="s">"kernel command line"</span><span class="p">)</span>
	<span class="k">return</span> <span class="n">cmd</span>
<span class="p">}</span>
</code></pre></div></div> <h2 id="appendix">Appendix</h2> <p><span id="jumpA"></span></p> <h3 id="tdvf-configurations">TDVF Configurations</h3> <p><strong>Config-A</strong>:</p> <ul> <li>Merge the <em>basic</em> TDVF feature to existing <code class="language-plaintext highlighter-rouge">OvmfX64Pkg.dsc</code>. (Align with existing SEV)</li> <li>Threat model: VMM is NOT out of TCB. (We don’t make things worse)</li> <li>The <code class="language-plaintext highlighter-rouge">OvmfX64Pkg.dsc</code> includes SEV/TDX/normal OVMF basic boot capability. The final binary can run on SEV/TDX/normal OVMF.</li> <li>No changes to existing OvmfPkgX64 image layout.</li> <li>No need to remove features if they exist today.</li> <li>PEI phase is NOT skipped in either TD or Non-TD.</li> <li>RTMR based measurement is supported.</li> <li>External inputs from Host VMM are measured, such as TdHob, CFV.</li> <li>Other external inputs are measured, such as FW_CFG data, os loader, initrd, etc.</li> </ul> <p><strong>Build the TDVF (Config-A) target:</strong></p> <p><a href="https://git.codelinaro.org/linaro/dcap/edk2/-/commit/4d37059d8e1eeda124270a158416795605327cbd">OvmfPkg: Support Tdx measurement in OvmfPkgX64</a></p> <div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">cd</span> /path/to/edk2
<span class="nb">source </span>edksetup.sh
build.sh <span class="nt">-p</span> OvmfPkg/OvmfPkgX64.dsc <span class="nt">-a</span> X64 <span class="nt">-t</span> GCC5
</code></pre></div></div> <p><strong>Config-B</strong>:</p> <ul> <li>Add a standalone <code class="language-plaintext highlighter-rouge">IntelTdx.dsc</code> to a TDX specific directory for a <em>full</em>  feature TDVF.(Align with existing SEV)</li> <li>Threat model: VMM is out of TCB. (We need necessary change to prevent attack from VMM)</li> <li><code class="language-plaintext highlighter-rouge">IntelTdx.dsc</code> includes TDX/normal OVMF basic boot capability. The final binary can run on TDX/normal OVMF.</li> <li>It might eventually merge with AmdSev.dsc, but NOT at this point of time. And we don’t know when it will happen. We need sync with AMD in the community after both of us think the solutions are mature to merge.</li> <li>Need to add necessary security feature as mandatory requirement, such as RTMR based Trusted Boot support.</li> <li>Need to measure the external input from Host VMM, such as TdHob, CFV.</li> <li>Need to measure other external input, such as FW_CFG data, os loader, initrd, etc.</li> <li>Need to remove unnecessary attack surfaces, such as network stack.</li> </ul> <p><strong>Build the TDVF (Config-B) target:</strong></p> <p><a href="https://git.codelinaro.org/linaro/dcap/edk2/-/commit/44a53a3bdd9c76e37f1750b5aa6a745de5d77391">OvmfPkg: Introduce IntelTdxX64 for TDVF Config-B</a></p> <div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">cd</span> /path/to/edk2
<span class="nb">set </span><span class="nv">PACKAGES_PATH</span><span class="o">=</span>/path/to/edk2/OvmfPkg
<span class="nb">source </span>edksetup.sh
build.sh <span class="nt">-p</span> OvmfPkg/IntelTdx/IntelTdxX64.dsc <span class="nt">-a</span> X64 <span class="nt">-t</span> GCC5
</code></pre></div></div> <p><span id="jumpB"></span></p> <h3 id="uefi-boot-phase">UEFI Boot Phase</h3> <p>UEFI has six main boot phases, which are all critical in the initialization process of the platform. The combined phases are referred to as the Platform Initialization or PI.</p> <p><em>1.</em> Security (SEC)</p> <p>This phase is the primary stage of the UEFI boot process, and will generally be used to: initialize a temporary memory store, act as the root of trust in the system and provide information to the Pre-EFI core phase. This root of trust is a mechanism that ensures any code that is executed in the PI is cryptographically validated (digitally signed), creating a “secure boot” environment.</p> <p><em>2.</em> Pre-EFI Initialization (PEI)</p> <p>This is the second stage of the boot process and involves using only the CPU’s current resources to dispatch Pre-EFI Initialization Modules (PEIMs). These are used to perform initialization of specific boot-critical operations such as memory initialization, whilst also allowing control to pass to the Driver Execution Environment (DXE).</p> <p><em>3.</em> Driver Execution Environment (DXE)</p> <p>The DXE phase is where the majority of the system initialization occurs. In the PEI stage, the memory required for the DXE to operate is allocated and initialized, and upon control being passed to the DXE, the DXE Dispatcher is then invoked. The dispatcher will perform the loading and execution of hardware drivers, runtime services, and any boot services required for the operating system to start.</p> <p><em>4.</em> Boot Device Selection (BDS)</p> <p>Upon completion of the DXE Dispatcher executing all DXE drivers, control is passed to the BDS. This stage is responsible for initializing console devices and any remaining devices that are required. The selected boot entry (OS loader) is then loaded and executed in preparation for the Transient System Load (TSL).</p> <p><em>5.</em> Transient System Load (TSL)</p> <p>In this phase, the PI process is now directly between the boot selection and the expected hand-off to the main operating system phase. Here, an application such as the UEFI shell may be invoked, or (more commonly) a boot loader will run in order to prepare the final OS environment. The boot loader is usually responsible for terminating the UEFI Boot Services via the ExitBootServices() call. However, it is also possible for the OS itself to do this, such as the Linux kernel with CONFIG_EFI_STUB.</p> <p><em>6.</em> Runtime (RT)</p> <p>The final phase is the runtime one. Here is where the final handoff to the OS occurs. The UEFI compatible OS now takes over the system. The UEFI runtime services remain available for the OS to use, such as for querying and writing variables from NVRAM.</p>]]></content><author><name></name></author><category term="cc"/><category term="tdx"/><category term="measurement"/><category term="attestation"/><summary type="html"><![CDATA[How to build a trusted chain when launch TD guest using grub boot.]]></summary></entry></feed>